import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®ä¸­æ–‡å­—é«”æ”¯æ´
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class MMWaveECGAnalyzer:
    """æ¯«ç±³æ³¢èˆ‡ECGç›¸ä¼¼åº¦åˆ†æå™¨"""
    
    def __init__(self, csv_file_path):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Parameters:
        csv_file_path (str): CSVæ–‡ä»¶è·¯å¾‘
        """
        self.data = pd.read_csv(csv_file_path, encoding='utf-8')
        self.results = {}
        self.best_data = {}
        
    def load_data(self):
        """è¼‰å…¥ä¸¦é è™•ç†æ•¸æ“š"""
        print("æ•¸æ“šè¼‰å…¥å®Œæˆï¼")
        print(f"ç¸½æ•¸æ“šç­†æ•¸: {len(self.data)}")
        print(f"æ•¸æ“šæ¬„ä½: {list(self.data.columns)}")
        
        # æª¢æŸ¥å„è·é›¢çš„æ•¸æ“šåˆ†å¸ƒ
        distance_counts = self.data['è·é›¢(cm)'].value_counts().sort_index()
        print("\nå„è·é›¢æ•¸æ“šåˆ†å¸ƒ:")
        for distance, count in distance_counts.items():
            print(f"{distance}cm: {count}ç­†")
        
        return self.data
    
    def calculate_composite_score(self, row, weighting_scheme='balanced'):
        """
        è¨ˆç®—ç¶œåˆè©•åˆ†
        
        Parameters:
        row (pd.Series): æ•¸æ“šè¡Œ
        weighting_scheme (str): æ¬Šé‡æ–¹æ¡ˆ
            - 'balanced': å¹³è¡¡æ–¹æ¡ˆ (33.3%, 33.3%, 33.3%)
            - 'shape_focused': å½¢ç‹€å°å‘ (60%, 20%, 20%)
            - 'correlation_focused': ç›¸é—œæ€§å°å‘ (20%, 40%, 40%)
            - 'dtw_dominant': DTWä¸»å° (70%, 15%, 15%)
            - 'equal_corr': ç›¸é—œæ€§å¹³ç­‰ (40%, 30%, 30%)
            - 'custom': è‡ªå®šç¾©æ¬Šé‡ (éœ€è¦é¡å¤–æŒ‡å®š)
        
        Returns:
        float: ç¶œåˆè©•åˆ†
        """
        # è¨ˆç®—å„å€‹æŒ‡æ¨™çš„æ¨™æº–åŒ–åˆ†æ•¸
        dtw_score = 1 / (1 + row['åŸå§‹_DTWè·é›¢']) if pd.notna(row['åŸå§‹_DTWè·é›¢']) else 0
        spearman_score = abs(row['åŸå§‹_Spearman']) if pd.notna(row['åŸå§‹_Spearman']) else 0
        cross_corr_score = abs(row['åŸå§‹_äº’ç›¸é—œ']) / 1000 if pd.notna(row['åŸå§‹_äº’ç›¸é—œ']) else 0
        
        # å®šç¾©ä¸åŒçš„æ¬Šé‡æ–¹æ¡ˆ
        weight_schemes = {
            'balanced': (1/3, 1/3, 1/3),
            'shape_focused': (0.6, 0.2, 0.2),
            'correlation_focused': (0.2, 0.4, 0.4),
            'dtw_dominant': (0.85, 0.075, 0.075),  # DTWçµ•å°ä¸»å° 85%
            'dtw_absolute': (0.90, 0.05, 0.05),   # DTWçµ•å°ä¸»å° 90%
            'dtw_extreme': (0.95, 0.025, 0.025),  # DTWæ¥µç«¯ä¸»å° 95%
            'equal_corr': (0.4, 0.3, 0.3),
            'literature_based': (0.5, 0.3, 0.2)
        }
        
        if weighting_scheme in weight_schemes:
            w_dtw, w_spearman, w_cross = weight_schemes[weighting_scheme]
        else:
            # é»˜èªä½¿ç”¨å¹³è¡¡æ–¹æ¡ˆ
            w_dtw, w_spearman, w_cross = weight_schemes['balanced']
        
        # è¨ˆç®—åŠ æ¬Šç¶œåˆåˆ†æ•¸
        composite_score = (dtw_score * w_dtw + 
                          spearman_score * w_spearman + 
                          cross_corr_score * w_cross)
        
        return composite_score
    
    def prepare_data(self, weighting_scheme='balanced'):
        """
        æº–å‚™æ•¸æ“šä¸¦è¨ˆç®—ç¶œåˆè©•åˆ†
        
        Parameters:
        weighting_scheme (str): æ¬Šé‡åˆ†é…æ–¹æ¡ˆ
        """
        # è¨ˆç®—ç¶œåˆè©•åˆ†
        self.data['ç¶œåˆè©•åˆ†'] = self.data.apply(
            lambda row: self.calculate_composite_score(row, weighting_scheme), axis=1
        )
        
        # æŒ‰è·é›¢åˆ†çµ„ï¼Œæ‰€æœ‰æ•¸æ“šéƒ½æ˜¯æœ€ä½³çš„
        distances = self.data['è·é›¢(cm)'].unique()
        
        print(f"\nä½¿ç”¨æ¬Šé‡æ–¹æ¡ˆ: {weighting_scheme}")
        weight_schemes_desc = {
            'balanced': 'DTW:33.3%, Spearman:33.3%, äº’ç›¸é—œ:33.3%',
            'shape_focused': 'DTW:60%, Spearman:20%, äº’ç›¸é—œ:20%',
            'correlation_focused': 'DTW:20%, Spearman:40%, äº’ç›¸é—œ:40%',
            'dtw_dominant': 'DTW:85%, Spearman:7.5%, äº’ç›¸é—œ:7.5%',
            'dtw_absolute': 'DTW:90%, Spearman:5%, äº’ç›¸é—œ:5%',
            'dtw_extreme': 'DTW:95%, Spearman:2.5%, äº’ç›¸é—œ:2.5%',
            'equal_corr': 'DTW:40%, Spearman:30%, äº’ç›¸é—œ:30%',
            'literature_based': 'DTW:50%, Spearman:30%, äº’ç›¸é—œ:20%'
        }
        print(f"æ¬Šé‡åˆ†é…: {weight_schemes_desc.get(weighting_scheme, 'è‡ªå®šç¾©')}")
        
        # æ‰€æœ‰æ•¸æ“šéƒ½ä¿ç•™ï¼ˆå·²ç¶“æ˜¯æœ€ä½³çš„25ç­†ï¼‰
        for distance in distances:
            distance_data = self.data[self.data['è·é›¢(cm)'] == distance].copy()
            self.best_data[distance] = distance_data
            print(f"\n{distance}cm - ä½¿ç”¨å…¨éƒ¨{len(distance_data)}ç­†æ•¸æ“š (å·²é å…ˆç¯©é¸çš„æœ€ä½³è³‡æ–™)")
    
    
    def compare_weighting_schemes(self, schemes_to_compare=None):
        """
        æ¯”è¼ƒä¸åŒæ¬Šé‡æ–¹æ¡ˆçš„çµæœ
        
        Parameters:
        schemes_to_compare (list): è¦æ¯”è¼ƒçš„æ¬Šé‡æ–¹æ¡ˆåˆ—è¡¨
        """
        if schemes_to_compare is None:
            schemes_to_compare = ['balanced', 'dtw_dominant', 'dtw_absolute', 'dtw_extreme']
        
        print("\n" + "="*100)
        print("ä¸åŒæ¬Šé‡æ–¹æ¡ˆæ¯”è¼ƒçµæœ (é‡é»ï¼šDTWçµ•å°ä¸»å°æ–¹æ¡ˆ)")
        print("="*100)
        
        scheme_results = {}
        
        for scheme in schemes_to_compare:
            print(f"\nğŸ“Š æ¬Šé‡æ–¹æ¡ˆ: {scheme}")
            
            # é¡¯ç¤ºå…·é«”æ¬Šé‡åˆ†é…
            weight_schemes_desc = {
                'balanced': 'DTW:33.3%, Spearman:33.3%, äº’ç›¸é—œ:33.3%',
                'dtw_dominant': 'DTW:85%, Spearman:7.5%, äº’ç›¸é—œ:7.5%',
                'dtw_absolute': 'DTW:90%, Spearman:5%, äº’ç›¸é—œ:5%',
                'dtw_extreme': 'DTW:95%, Spearman:2.5%, äº’ç›¸é—œ:2.5%',
                'shape_focused': 'DTW:60%, Spearman:20%, äº’ç›¸é—œ:20%',
                'correlation_focused': 'DTW:20%, Spearman:40%, äº’ç›¸é—œ:40%'
            }
            
            print(f"    æ¬Šé‡åˆ†é…: {weight_schemes_desc.get(scheme, 'æœªå®šç¾©')}")
            print("-" * 80)
            
            # é‡æ–°è¨ˆç®—ç¶œåˆè©•åˆ†
            temp_data = self.data.copy()
            temp_data['ç¶œåˆè©•åˆ†'] = temp_data.apply(
                lambda row: self.calculate_composite_score(row, scheme), axis=1
            )
            
            # è¨ˆç®—å„è·é›¢çš„å¹³å‡ç¶œåˆè©•åˆ†
            distance_avg_scores = {}
            for distance in temp_data['è·é›¢(cm)'].unique():
                distance_data = temp_data[temp_data['è·é›¢(cm)'] == distance]
                top_25 = distance_data.nlargest(25, 'ç¶œåˆè©•åˆ†')
                avg_score = top_25['ç¶œåˆè©•åˆ†'].mean()
                distance_avg_scores[distance] = avg_score
            
            # æ’åºä¸¦é¡¯ç¤ºçµæœ
            sorted_distances = sorted(distance_avg_scores.items(), key=lambda x: x[1], reverse=True)
            
            for rank, (distance, score) in enumerate(sorted_distances, 1):
                status = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else f"{rank}."
                print(f"    {status} {distance}cm: {score:.6f}")
            
            scheme_results[scheme] = {
                'best_distance': sorted_distances[0][0],
                'rankings': sorted_distances
            }
        
        # ç¸½çµæ¯”è¼ƒ
        print(f"\nğŸ“‹ DTWä¸»å°æ¬Šé‡æ–¹æ¡ˆå°æœ€ä½³è·é›¢çš„å½±éŸ¿:")
        print("-" * 60)
        for scheme, result in scheme_results.items():
            weight_desc = {
                'balanced': 'å¹³è¡¡æ–¹æ¡ˆ',
                'dtw_dominant': 'DTWä¸»å°(85%)',
                'dtw_absolute': 'DTWçµ•å°ä¸»å°(90%)',
                'dtw_extreme': 'DTWæ¥µç«¯ä¸»å°(95%)'
            }
            desc = weight_desc.get(scheme, scheme)
            print(f"{desc:15s} â†’ æœ€ä½³è·é›¢: {result['best_distance']}cm")
        
        # DTWæ¬Šé‡å½±éŸ¿åˆ†æ
        print(f"\nğŸ” DTWæ¬Šé‡å°çµæœç©©å®šæ€§çš„åˆ†æ:")
        print("-" * 60)
        best_distances = [result['best_distance'] for result in scheme_results.values()]
        if len(set(best_distances)) == 1:
            print("âœ… æ‰€æœ‰DTWä¸»å°æ–¹æ¡ˆéƒ½æŒ‡å‘ç›¸åŒçš„æœ€ä½³è·é›¢ï¼Œçµæœéå¸¸ç©©å®š")
        elif len(set(best_distances)) == 2:
            print("âš ï¸  DTWä¸»å°æ–¹æ¡ˆå­˜åœ¨è¼•å¾®åˆ†æ­§ï¼Œå»ºè­°é€²ä¸€æ­¥æª¢æŸ¥")
        else:
            print("âŒ DTWä¸»å°æ–¹æ¡ˆçµæœä¸ä¸€è‡´ï¼Œå¯èƒ½éœ€è¦æ›´ä»”ç´°çš„åˆ†æ")
        
        return scheme_results
    
    def calculate_statistics(self):
        """è¨ˆç®—å„è·é›¢çš„çµ±è¨ˆæŒ‡æ¨™"""
        
        for distance, data in self.best_data.items():
            # æå–å„æŒ‡æ¨™æ•¸æ“š
            dtw_values = data['åŸå§‹_DTWè·é›¢'].dropna()
            spearman_values = data['åŸå§‹_Spearman'].dropna()
            cross_corr_values = data['åŸå§‹_äº’ç›¸é—œ'].dropna()
            composite_scores = data['ç¶œåˆè©•åˆ†'].dropna()
            
            # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
            stats_dict = {
                'dtw': {
                    'mean': dtw_values.mean(),
                    'std': dtw_values.std(),
                    'median': dtw_values.median(),
                    'min': dtw_values.min(),
                    'max': dtw_values.max()
                },
                'spearman': {
                    'mean': spearman_values.mean(),
                    'std': spearman_values.std(),
                    'abs_mean': abs(spearman_values).mean(),
                    'median': spearman_values.median(),
                    'min': spearman_values.min(),
                    'max': spearman_values.max()
                },
                'cross_corr': {
                    'mean': cross_corr_values.mean(),
                    'std': cross_corr_values.std(),
                    'abs_mean': abs(cross_corr_values).mean(),
                    'median': cross_corr_values.median(),
                    'min': cross_corr_values.min(),
                    'max': cross_corr_values.max()
                },
                'composite': {
                    'mean': composite_scores.mean(),
                    'std': composite_scores.std(),
                    'median': composite_scores.median(),
                    'scores': composite_scores.tolist()
                }
            }
            
            self.results[distance] = stats_dict
    
    def create_statistics_table(self):
        """å‰µå»ºçµ±è¨ˆçµæœè¡¨æ ¼"""
        
        # æº–å‚™è¡¨æ ¼æ•¸æ“š
        table_data = []
        
        for distance, stats in self.results.items():
            # è¨ˆç®—ç¶œåˆè¡¨ç¾åˆ†æ•¸ (ç”¨æ–¼æ’å)
            performance_score = (1/stats['dtw']['mean'] * 0.4 + 
                               stats['spearman']['abs_mean'] * 0.3 + 
                               stats['cross_corr']['abs_mean']/1000 * 0.3)
            
            table_data.append({
                'è·é›¢(cm)': distance,
                'DTWè·é›¢_å¹³å‡': f"{stats['dtw']['mean']:.3f}",
                'DTWè·é›¢_æ¨™æº–å·®': f"{stats['dtw']['std']:.3f}",
                'Spearman_å¹³å‡': f"{stats['spearman']['mean']:.4f}",
                'Spearman_æ¨™æº–å·®': f"{stats['spearman']['std']:.4f}",
                'äº’ç›¸é—œ_å¹³å‡': f"{stats['cross_corr']['mean']:.1f}",
                'äº’ç›¸é—œ_æ¨™æº–å·®': f"{stats['cross_corr']['std']:.1f}",
                'ç¶œåˆè¡¨ç¾åˆ†æ•¸': f"{performance_score:.4f}",
                'æ’åç”¨åˆ†æ•¸': performance_score
            })
        
        # è½‰æ›ç‚ºDataFrameä¸¦æŒ‰è¡¨ç¾åˆ†æ•¸æ’åº
        df_table = pd.DataFrame(table_data)
        df_table = df_table.sort_values('æ’åç”¨åˆ†æ•¸', ascending=False)
        df_table['æ’å'] = range(1, len(df_table) + 1)
        
        # é‡æ–°æ’åˆ—æ¬„ä½é †åº
        df_display = df_table[['æ’å', 'è·é›¢(cm)', 'DTWè·é›¢_å¹³å‡', 'DTWè·é›¢_æ¨™æº–å·®', 
                              'Spearman_å¹³å‡', 'Spearman_æ¨™æº–å·®', 'äº’ç›¸é—œ_å¹³å‡', 
                              'äº’ç›¸é—œ_æ¨™æº–å·®', 'ç¶œåˆè¡¨ç¾åˆ†æ•¸']].copy()
        
        print("\n" + "="*100)
        print("çµ±è¨ˆçµæœè¡¨æ ¼ (åŸºæ–¼æœ€ä½³25ç­†æ•¸æ“š)")
        print("="*100)
        print(df_display.to_string(index=False, float_format='%.4f'))
        
        return df_display
    
    def perform_statistical_tests(self, save_plots=True):
        """é€²è¡Œçµ±è¨ˆå‡è¨­æª¢å®š"""
        
        print("\n" + "="*80)
        print("çµ±è¨ˆå‡è¨­æª¢å®šçµæœ")
        print("="*80)
        
        distances = list(self.results.keys())
        
        # æº–å‚™å­˜å„²çµæœçš„æ•¸æ“šçµæ§‹
        t_test_results = []
        wilcoxon_results = []
        comparison_pairs = []
        
        # å°ç¶œåˆè©•åˆ†é€²è¡Œé…å°æ¯”è¼ƒ
        print("\n1. ç¶œåˆè©•åˆ†çš„é…å°tæª¢å®šçµæœ:")
        print("-" * 50)
        
        for i in range(len(distances)):
            for j in range(i+1, len(distances)):
                dist1, dist2 = distances[i], distances[j]
                scores1 = self.results[dist1]['composite']['scores']
                scores2 = self.results[dist2]['composite']['scores']
                
                # é€²è¡Œç¨ç«‹æ¨£æœ¬tæª¢å®š
                t_stat, p_value = stats.ttest_ind(scores1, scores2)
                
                significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
                
                print(f"{dist1}cm vs {dist2}cm: t={t_stat:.3f}, p={p_value:.4f} {significance}")
                
                # å­˜å„²çµæœ
                comparison_pairs.append(f"{dist1}cm vs {dist2}cm")
                t_test_results.append(p_value)
        
        # Wilcoxonæª¢å®š (éåƒæ•¸æª¢å®š)
        print("\n2. ç¶œåˆè©•åˆ†çš„Wilcoxonç§©å’Œæª¢å®šçµæœ:")
        print("-" * 50)
        
        for i in range(len(distances)):
            for j in range(i+1, len(distances)):
                dist1, dist2 = distances[i], distances[j]
                scores1 = self.results[dist1]['composite']['scores']
                scores2 = self.results[dist2]['composite']['scores']
                
                # é€²è¡ŒWilcoxonç§©å’Œæª¢å®š
                u_stat, p_value = stats.mannwhitneyu(scores1, scores2, alternative='two-sided')
                
                significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else "ns"
                
                print(f"{dist1}cm vs {dist2}cm: U={u_stat:.3f}, p={p_value:.4f} {significance}")
                
                # å­˜å„²çµæœ
                wilcoxon_results.append(p_value)
        
        print("\nè¨»: *** p<0.001, ** p<0.01, * p<0.05, ns=ä¸é¡¯è‘—")
        
        # å‰µå»ºçµ±è¨ˆæª¢å®šçµæœçš„è¦–è¦ºåŒ–
        if save_plots:
            self.create_statistical_test_visualization(comparison_pairs, t_test_results, wilcoxon_results)
    
    def create_statistical_test_visualization(self, comparison_pairs, t_test_results, wilcoxon_results):
        """å‰µå»ºçµ±è¨ˆæª¢å®šçµæœçš„è¦–è¦ºåŒ–åœ–è¡¨"""
        
        import matplotlib
        matplotlib.use('Agg')  # ä½¿ç”¨éGUIå¾Œç«¯
        
        # å‰µå»ºåœ–è¡¨
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
        
        # è¨­ç½®é¡è‰²æ˜ å°„ (åŸºæ–¼på€¼çš„é¡¯è‘—æ€§æ°´å¹³)
        def get_color(p_value):
            if p_value < 0.001:
                return 'red'  # æ¥µé¡¯è‘—
            elif p_value < 0.01:
                return 'orange'  # é«˜åº¦é¡¯è‘—
            elif p_value < 0.05:
                return 'yellow'  # é¡¯è‘—
            else:
                return 'lightgray'  # ä¸é¡¯è‘—
        
        def get_significance_label(p_value):
            if p_value < 0.001:
                return '***'
            elif p_value < 0.01:
                return '**'
            elif p_value < 0.05:
                return '*'
            else:
                return 'ns'
        
        # åœ–1: tæª¢å®šçµæœæ¢å½¢åœ–
        colors_t = [get_color(p) for p in t_test_results]
        bars1 = ax1.bar(range(len(comparison_pairs)), t_test_results, color=colors_t, alpha=0.7, edgecolor='black')
        ax1.set_title('T-Test Results (p-values)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Comparison Pairs')
        ax1.set_ylabel('p-value')
        ax1.set_xticks(range(len(comparison_pairs)))
        ax1.set_xticklabels(comparison_pairs, rotation=45, ha='right')
        ax1.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='Î± = 0.05')
        ax1.axhline(y=0.01, color='orange', linestyle='--', alpha=0.7, label='Î± = 0.01')
        ax1.axhline(y=0.001, color='darkred', linestyle='--', alpha=0.7, label='Î± = 0.001')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ é¡¯è‘—æ€§æ¨™è¨˜
        for i, (bar, p_val) in enumerate(zip(bars1, t_test_results)):
            height = bar.get_height()
            sig_label = get_significance_label(p_val)
            ax1.text(bar.get_x() + bar.get_width()/2, height + max(t_test_results)*0.01,
                    sig_label, ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        # åœ–2: Wilcoxonæª¢å®šçµæœæ¢å½¢åœ–
        colors_w = [get_color(p) for p in wilcoxon_results]
        bars2 = ax2.bar(range(len(comparison_pairs)), wilcoxon_results, color=colors_w, alpha=0.7, edgecolor='black')
        ax2.set_title('Wilcoxon Rank-Sum Test Results (p-values)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Comparison Pairs')
        ax2.set_ylabel('p-value')
        ax2.set_xticks(range(len(comparison_pairs)))
        ax2.set_xticklabels(comparison_pairs, rotation=45, ha='right')
        ax2.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='Î± = 0.05')
        ax2.axhline(y=0.01, color='orange', linestyle='--', alpha=0.7, label='Î± = 0.01')
        ax2.axhline(y=0.001, color='darkred', linestyle='--', alpha=0.7, label='Î± = 0.001')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ é¡¯è‘—æ€§æ¨™è¨˜
        for i, (bar, p_val) in enumerate(zip(bars2, wilcoxon_results)):
            height = bar.get_height()
            sig_label = get_significance_label(p_val)
            ax2.text(bar.get_x() + bar.get_width()/2, height + max(wilcoxon_results)*0.01,
                    sig_label, ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        # åœ–3: æ¯”è¼ƒå…©ç¨®æª¢å®šæ–¹æ³•çš„på€¼æ•£é»åœ–
        ax3.scatter(t_test_results, wilcoxon_results, alpha=0.7, s=100, edgecolor='black')
        ax3.set_title('T-Test vs Wilcoxon Test Comparison', fontsize=14, fontweight='bold')
        ax3.set_xlabel('T-Test p-values')
        ax3.set_ylabel('Wilcoxon Test p-values')
        ax3.plot([0, 1], [0, 1], 'r--', alpha=0.7, label='y = x')
        ax3.axhline(y=0.05, color='red', linestyle='--', alpha=0.5)
        ax3.axvline(x=0.05, color='red', linestyle='--', alpha=0.5)
        ax3.grid(True, alpha=0.3)
        ax3.legend()
        
        # æ·»åŠ æ¯å€‹é»çš„æ¨™ç±¤
        for i, (t_p, w_p, pair) in enumerate(zip(t_test_results, wilcoxon_results, comparison_pairs)):
            ax3.annotate(pair, (t_p, w_p), xytext=(5, 5), textcoords='offset points', 
                        fontsize=8, alpha=0.8)
        
        # è¨­ç½®å°æ•¸å°ºåº¦ä»¥æ›´å¥½åœ°é¡¯ç¤ºå°på€¼
        if min(t_test_results + wilcoxon_results) > 0:
            ax1.set_yscale('log')
            ax2.set_yscale('log')
            ax3.set_xscale('log')
            ax3.set_yscale('log')
        
        plt.tight_layout()
        plt.savefig('statistical_tests_results.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š çµ±è¨ˆæª¢å®šçµæœåœ–è¡¨å·²å„²å­˜ç‚º: statistical_tests_results.png")
        plt.close()
    
    def create_visualizations(self, save_plots=True):
        """å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨"""
        
        # è¨­ç½®åœ–è¡¨æ¨£å¼
        import matplotlib
        matplotlib.use('Agg')  # ä½¿ç”¨éGUIå¾Œç«¯
        plt.style.use('default')
        fig = plt.figure(figsize=(16, 12))
        
        # æº–å‚™æ•¸æ“š
        distances = list(self.results.keys())
        dtw_means = [self.results[d]['dtw']['mean'] for d in distances]
        dtw_stds = [self.results[d]['dtw']['std'] for d in distances]
        spearman_abs_means = [self.results[d]['spearman']['abs_mean'] for d in distances]
        spearman_stds = [self.results[d]['spearman']['std'] for d in distances]
        cross_corr_abs_means = [self.results[d]['cross_corr']['abs_mean'] for d in distances]
        cross_corr_stds = [self.results[d]['cross_corr']['std'] for d in distances]
        composite_means = [self.results[d]['composite']['mean'] for d in distances]
        
        # å­åœ–1: DTWè·é›¢æ¯”è¼ƒ
        plt.subplot(2, 3, 1)
        bars1 = plt.bar(distances, dtw_means, yerr=dtw_stds, capsize=5, 
                       color='lightcoral', alpha=0.7, edgecolor='darkred')
        plt.title('DTW Distance Comparison (Lower is Better)', fontsize=12, fontweight='bold')
        plt.xlabel('Distance (cm)')
        plt.ylabel('DTW Distance')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, mean in zip(bars1, dtw_means):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.05,
                    f'{mean:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # å­åœ–2: Spearmanç›¸é—œä¿‚æ•¸æ¯”è¼ƒ
        plt.subplot(2, 3, 2)
        bars2 = plt.bar(distances, spearman_abs_means, yerr=spearman_stds, capsize=5,
                       color='lightblue', alpha=0.7, edgecolor='darkblue')
        plt.title('|Spearman Correlation| Comparison (Higher is Better)', fontsize=12, fontweight='bold')
        plt.xlabel('Distance (cm)')
        plt.ylabel('|Spearman Correlation Coefficient|')
        plt.grid(True, alpha=0.3)
        
        for bar, mean in zip(bars2, spearman_abs_means):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.05,
                    f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # å­åœ–3: äº’ç›¸é—œä¿‚æ•¸æ¯”è¼ƒ
        plt.subplot(2, 3, 3)
        bars3 = plt.bar(distances, cross_corr_abs_means, yerr=cross_corr_stds, capsize=5,
                       color='lightgreen', alpha=0.7, edgecolor='darkgreen')
        plt.title('|Cross-Correlation| Comparison (Higher is Better)', fontsize=12, fontweight='bold')
        plt.xlabel('Distance (cm)')
        plt.ylabel('|Cross-Correlation Coefficient|')
        plt.grid(True, alpha=0.3)
        
        for bar, mean in zip(bars3, cross_corr_abs_means):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.05,
                    f'{mean:.0f}', ha='center', va='bottom', fontweight='bold')
        
        # å­åœ–4: ç¶œåˆè©•åˆ†æ¯”è¼ƒ
        plt.subplot(2, 3, 4)
        bars4 = plt.bar(distances, composite_means, color='gold', alpha=0.7, edgecolor='orange')
        plt.title('Composite Score Comparison', fontsize=12, fontweight='bold', pad=20)
        plt.xlabel('Distance (cm)')
        plt.ylabel('Composite Score')
        plt.grid(True, alpha=0.3)
        
        # æ¨™è¨˜æœ€ä½³çµæœ
        best_idx = np.argmax(composite_means)
        bars4[best_idx].set_color('red')
        bars4[best_idx].set_alpha(0.8)
        
        for bar, mean in zip(bars4, composite_means):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.05,
                    f'{mean:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # å­åœ–5: ç¶œåˆè©•åˆ†åˆ†å¸ƒç®±ç·šåœ–
        plt.subplot(2, 3, 5)
        composite_data = [self.results[d]['composite']['scores'] for d in distances]
        box_plot = plt.boxplot(composite_data, labels=distances, patch_artist=True)
        
        # è¨­ç½®ç®±ç·šåœ–é¡è‰²
        colors = ['lightcoral', 'lightblue', 'lightgreen', 'gold']
        for patch, color in zip(box_plot['boxes'], colors[:len(distances)]):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        plt.title('Composite Score Distribution', fontsize=12, fontweight='bold', pad=20)
        plt.xlabel('Distance (cm)')
        plt.ylabel('Composite Score')
        plt.grid(True, alpha=0.3)
        
        # å­åœ–6: é›·é”åœ–
        plt.subplot(2, 3, 6, projection='polar')
        
        # æº–å‚™é›·é”åœ–æ•¸æ“š (æ¨™æº–åŒ–)
        categories = ['DTW\n(Inverted)', 'Spearman\n(Absolute)', 'Cross-Correlation\n(Absolute)', 'Composite\nScore']
        N = len(categories)
        
        # è¨ˆç®—è§’åº¦
        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]  # é–‰åˆåœ–å½¢
        
        for i, distance in enumerate(distances):
            # æ¨™æº–åŒ–æ•¸æ“š (0-1ç¯„åœ)
            values = [
                1 - (self.results[distance]['dtw']['mean'] - min(dtw_means)) / (max(dtw_means) - min(dtw_means)),  # DTWåå‘
                (self.results[distance]['spearman']['abs_mean'] - min(spearman_abs_means)) / (max(spearman_abs_means) - min(spearman_abs_means)),
                (self.results[distance]['cross_corr']['abs_mean'] - min(cross_corr_abs_means)) / (max(cross_corr_abs_means) - min(cross_corr_abs_means)),
                (self.results[distance]['composite']['mean'] - min(composite_means)) / (max(composite_means) - min(composite_means))
            ]
            values += values[:1]  # é–‰åˆåœ–å½¢
            
            plt.plot(angles, values, 'o-', linewidth=2, label=f'{distance}cm', alpha=0.7)
            plt.fill(angles, values, alpha=0.1)
        
        plt.xticks(angles[:-1], categories)
        plt.ylim(0, 1)
        plt.title('Multi-Distance Performance Radar Chart', fontsize=12, fontweight='bold', pad=40)
        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
        
        # èª¿æ•´å­åœ–é–“è·ï¼Œç‰¹åˆ¥å¢åŠ å‚ç›´é–“è·ä»¥é¿å…æ¨™é¡Œèˆ‡åœ–ç‰‡é‡ç–Š
        plt.tight_layout(pad=4.0, h_pad=4.0, w_pad=2.5)
        if save_plots:
            plt.savefig('mmwave_analysis_results.png', dpi=300, bbox_inches='tight')
            print("ğŸ“Š åœ–è¡¨å·²å„²å­˜ç‚º: mmwave_analysis_results.png")
        else:
            plt.show()
    
    def generate_conclusion(self):
        """ç”Ÿæˆçµè«–å ±å‘Š"""
        
        # æ‰¾å‡ºæœ€ä½³è·é›¢
        distances = list(self.results.keys())
        composite_means = [self.results[d]['composite']['mean'] for d in distances]
        best_idx = np.argmax(composite_means)
        best_distance = distances[best_idx]
        best_score = composite_means[best_idx]
        
        # æ’åºæ‰€æœ‰è·é›¢
        distance_scores = [(d, self.results[d]['composite']['mean']) for d in distances]
        distance_scores.sort(key=lambda x: x[1], reverse=True)
        
        print("\n" + "="*80)
        print("ğŸ† ç ”ç©¶çµè«–èˆ‡å»ºè­°")
        print("="*80)
        
        print(f"\nâœ… æœ€ä½³æ¸¬é‡è·é›¢: {best_distance}cm")
        print(f"   ç¶œåˆè©•åˆ†: {best_score:.4f}")
        print(f"   DTWè·é›¢: {self.results[best_distance]['dtw']['mean']:.3f} Â± {self.results[best_distance]['dtw']['std']:.3f}")
        print(f"   Spearmanç›¸é—œ: {self.results[best_distance]['spearman']['mean']:.4f} Â± {self.results[best_distance]['spearman']['std']:.4f}")
        print(f"   äº’ç›¸é—œä¿‚æ•¸: {self.results[best_distance]['cross_corr']['mean']:.1f} Â± {self.results[best_distance]['cross_corr']['std']:.1f}")
        
        print("\nğŸ“Š å„è·é›¢è¡¨ç¾æ’å:")
        for i, (distance, score) in enumerate(distance_scores, 1):
            status = "ğŸ¥‡ æœ€ä½³" if i == 1 else "ğŸ¥ˆ æ¬¡ä½³" if i == 2 else "ğŸ¥‰ ç¬¬ä¸‰" if i == 3 else f"   ç¬¬{i}"
            print(f"   {status}: {distance}cm (è©•åˆ†: {score:.4f})")
        
        print("\nğŸ“‹ å­¸è¡“å»ºè­°:")
        print("   1. çµ±è¨ˆé¡¯è‘—æ€§: å»ºè­°é€²è¡Œé…å°tæª¢å®šé©—è­‰å„è·é›¢é–“å·®ç•°")
        print("   2. æ¨£æœ¬å¤§å°: å»ºè­°å¢åŠ æ¨£æœ¬æ•¸é‡ä»¥æé«˜çµ±è¨ˆåŠŸæ•ˆ")
        print(f"   3. å¯¦ç”¨å»ºè­°: åœ¨{best_distance}cmè·é›¢ä¸‹æ¯«ç±³æ³¢é›·é”æª¢æ¸¬æ•ˆæœæœ€ä½³")
        print(f"   4. å„ªåŒ–ç¯„åœ: å¯åœ¨{best_distance}cm Â± 10cmç¯„åœå…§é€²ä¸€æ­¥å„ªåŒ–")
        
        return best_distance, distance_scores
    
    def run_complete_analysis(self, top_n=25, weighting_scheme='balanced', compare_schemes=True):
        """
        é‹è¡Œå®Œæ•´åˆ†ææµç¨‹
        
        Parameters:
        top_n (int): é¸å–çš„æœ€ä½³æ•¸æ“šç­†æ•¸
        weighting_scheme (str): ä½¿ç”¨çš„æ¬Šé‡æ–¹æ¡ˆ
        compare_schemes (bool): æ˜¯å¦æ¯”è¼ƒä¸åŒæ¬Šé‡æ–¹æ¡ˆ
        """
        
        print("é–‹å§‹æ¯«ç±³æ³¢èˆ‡ECGç›¸ä¼¼åº¦åˆ†æ...")
        print("="*80)
        
        # 1. è¼‰å…¥æ•¸æ“š
        self.load_data()
        
        # 2. æ¯”è¼ƒä¸åŒæ¬Šé‡æ–¹æ¡ˆ (å¦‚æœè¦æ±‚)
        if compare_schemes:
            scheme_comparison = self.compare_weighting_schemes()
        
        # 3. æº–å‚™æ•¸æ“š (æ•¸æ“šå·²é å…ˆç¯©é¸)
        self.prepare_data(weighting_scheme)
        
        # 4. è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        self.calculate_statistics()
        
        # 5. å‰µå»ºçµ±è¨ˆè¡¨æ ¼
        stats_table = self.create_statistics_table()
        
        # 6. é€²è¡Œçµ±è¨ˆæª¢å®š
        self.perform_statistical_tests(save_plots=True)
        
        # 7. å‰µå»ºè¦–è¦ºåŒ–
        self.create_visualizations(save_plots=True)
        
        # 8. ç”Ÿæˆçµè«–
        best_distance, rankings = self.generate_conclusion()
        
        # 9. æ¬Šé‡æ•æ„Ÿæ€§åˆ†æ
        print("\n" + "="*80)
        print("ğŸ” æ¬Šé‡æ•æ„Ÿæ€§åˆ†æå»ºè­°")
        print("="*80)
        print("ä¸åŒæ¬Šé‡æ–¹æ¡ˆå¯èƒ½å°è‡´ä¸åŒçš„æœ€ä½³è·é›¢é¸æ“‡ã€‚å»ºè­°:")
        print("1. æ ¹æ“šç ”ç©¶ç›®æ¨™é¸æ“‡åˆé©çš„æ¬Šé‡æ–¹æ¡ˆ")
        print("2. é€²è¡Œæ•æ„Ÿæ€§åˆ†æï¼Œæª¢é©—çµæœçš„ç©©å¥æ€§")
        print("3. è€ƒæ…®ä½¿ç”¨å°ˆå®¶è©•ä¼°æˆ–æ–‡ç»ä¾æ“šä¾†ç¢ºå®šæ¬Šé‡")
        print("4. å¯ä»¥ä½¿ç”¨ä¸»æˆåˆ†åˆ†æ(PCA)ä¾†å®¢è§€ç¢ºå®šæ¬Šé‡")
        
        result_dict = {
            'best_distance': best_distance,
            'rankings': rankings,
            'statistics_table': stats_table,
            'detailed_results': self.results,
            'weighting_scheme': weighting_scheme
        }
        
        if compare_schemes:
            result_dict['scheme_comparison'] = scheme_comparison
            
        return result_dict

# æ¬Šé‡æ–¹æ¡ˆçš„ç†è«–ä¾æ“šå’Œå»ºè­°
def get_weighting_recommendations():
    """
    æä¾›æ¬Šé‡åˆ†é…çš„ç†è«–ä¾æ“šå’Œå»ºè­°
    """
    recommendations = {
        'research_goals': {
            'heart_rate_detection': {
                'description': 'ä¸»è¦é—œæ³¨å¿ƒç‡æª¢æ¸¬æº–ç¢ºæ€§',
                'recommended_scheme': 'dtw_absolute',
                'rationale': 'DTWè·é›¢90%æ¬Šé‡ï¼Œå°ˆæ³¨æ–¼æ³¢å½¢å½¢ç‹€çš„ç²¾ç¢ºåŒ¹é…'
            },
            'signal_quality_assessment': {
                'description': 'ä¿¡è™Ÿè³ªé‡è©•ä¼°',
                'recommended_scheme': 'dtw_extreme',
                'rationale': 'DTWè·é›¢95%æ¬Šé‡ï¼Œæ˜¯è©•ä¼°ä¿¡è™Ÿè³ªé‡çš„æœ€ç›´æ¥æŒ‡æ¨™'
            },
            'waveform_similarity': {
                'description': 'æ³¢å½¢ç›¸ä¼¼åº¦åˆ†æ',
                'recommended_scheme': 'dtw_dominant',
                'rationale': 'DTWè·é›¢85%æ¬Šé‡ï¼Œä¸»è¦è©•ä¼°æ™‚é–“åºåˆ—å½¢ç‹€åŒ¹é…åº¦'
            },
            'heart_rate_variability': {
                'description': 'é—œæ³¨å¿ƒç‡è®Šç•°æ€§åˆ†æ',
                'recommended_scheme': 'correlation_focused',
                'rationale': 'ç›¸é—œæ€§æŒ‡æ¨™æ›´é©åˆè©•ä¼°å¿ƒç‡è®Šç•°çš„ä¸€è‡´æ€§'
            },
            'general_cardiac_monitoring': {
                'description': 'ä¸€èˆ¬å¿ƒè‡Ÿç›£æ¸¬æ‡‰ç”¨',
                'recommended_scheme': 'balanced',
                'rationale': 'å¹³è¡¡è€ƒæ…®æ‰€æœ‰æŒ‡æ¨™ï¼Œé¿å…åå‘æ€§'
            },
            'signal_quality_assessment': {
                'description': 'ä¿¡è™Ÿè³ªé‡è©•ä¼°',
                'recommended_scheme': 'dtw_extreme',
                'rationale': 'DTWè·é›¢95%æ¬Šé‡ï¼Œæ˜¯è©•ä¼°ä¿¡è™Ÿè³ªé‡çš„æœ€ç›´æ¥æŒ‡æ¨™'
            }
        },
        'literature_based': {
            'description': 'åŸºæ–¼DTWçµ•å°ä¸»å°çš„æ¬Šé‡åˆ†é…',
            'dtw_weight': '85-95%',
            'correlation_weight': '2.5-7.5%',
            'rationale': 'å°ˆæ³¨æ–¼æ™‚é–“åºåˆ—æ³¢å½¢ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–å…¶ä»–å› ç´ å¹²æ“¾'
        },
        'data_driven_approaches': [
            'ä¸»æˆåˆ†åˆ†æ(PCA): åŸºæ–¼æ•¸æ“šç‰¹å¾µè‡ªå‹•ç¢ºå®šæ¬Šé‡',
            'æ©Ÿå™¨å­¸ç¿’æ–¹æ³•: ä½¿ç”¨ç›£ç£å­¸ç¿’å„ªåŒ–æ¬Šé‡',
            'å°ˆå®¶è©•ä¼°: çµåˆé ˜åŸŸå°ˆå®¶æ„è¦‹ç¢ºå®šæ¬Šé‡',
            'æ•æ„Ÿæ€§åˆ†æ: æ¸¬è©¦ä¸åŒæ¬Šé‡å°çµæœçš„å½±éŸ¿'
        ]
    }
    
    return recommendations

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # é¡¯ç¤ºæ¬Šé‡é¸æ“‡å»ºè­°
    print("="*80)
    print("æ¬Šé‡åˆ†é…é¸æ“‡æŒ‡å—")
    print("="*80)
    
    recommendations = get_weighting_recommendations()
    
    print("\nğŸ¯ æ ¹æ“šç ”ç©¶ç›®æ¨™é¸æ“‡æ¬Šé‡æ–¹æ¡ˆ:")
    for goal, info in recommendations['research_goals'].items():
        print(f"\nâ€¢ {info['description']}")
        print(f"  æ¨è–¦æ–¹æ¡ˆ: {info['recommended_scheme']}")
        print(f"  ç†ç”±: {info['rationale']}")
    
    print(f"\nï¿½ æ–‡ç»ä¾æ“š:")
    lit_info = recommendations['literature_based']
    print(f"  {lit_info['description']}")
    print(f"  DTWæ¬Šé‡: {lit_info['dtw_weight']}")
    print(f"  ç›¸é—œæ€§æ¬Šé‡: {lit_info['correlation_weight']}")
    print(f"  ç†ç”±: {lit_info['rationale']}")
    
    print(f"\nğŸ”¬ æ•¸æ“šé©…å‹•æ–¹æ³•:")
    for method in recommendations['data_driven_approaches']:
        print(f"  â€¢ {method}")
    
    print("\n" + "="*80)
    
    # å‰µå»ºåˆ†æå™¨å¯¦ä¾‹
    analyzer = MMWaveECGAnalyzer('/path/to/analysis_results.csv')  # è«‹æ›¿æ›ç‚ºæ‚¨çš„CSVæ–‡ä»¶è·¯å¾‘
    
    # é‹è¡Œå®Œæ•´åˆ†æ (ä½¿ç”¨DTWçµ•å°ä¸»å°æ–¹æ¡ˆ)
    results = analyzer.run_complete_analysis(
        top_n=25, 
        weighting_scheme='dtw_absolute',  # DTW 90%æ¬Šé‡
        compare_schemes=True
    )
    
    # è¼¸å‡ºæœ€ä½³è·é›¢
    print(f"\nğŸ¯ ä½¿ç”¨DTWçµ•å°ä¸»å°æ–¹æ¡ˆ({results['weighting_scheme']})çš„æœ€çµ‚å»ºè­°: {results['best_distance']}cm")
    print("ğŸ“Š DTWæ¬Šé‡90%ï¼Œå°ˆæ³¨æ–¼æ³¢å½¢å½¢ç‹€çš„ç²¾ç¢ºåŒ¹é…")
