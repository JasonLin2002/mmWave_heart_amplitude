# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
import os
import glob
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, callbacks
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, Dropout, Input
from tensorflow.keras.optimizers import Adam
import pickle
import warnings
warnings.filterwarnings('ignore')

# è¨­å®š TensorFlow GPU ä½¿ç”¨
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"æ‰¾åˆ° {len(gpus)} å€‹ GPUï¼Œå·²è¨­å®šå‹•æ…‹è¨˜æ†¶é«”åˆ†é…")
    except RuntimeError as e:
        print(f"GPU è¨­å®šéŒ¯èª¤: {e}")
else:
    print("æœªæ‰¾åˆ° GPUï¼Œå°‡ä½¿ç”¨ CPU é€²è¡Œè¨“ç·´")

# %% [markdown]
# ## 1. æ•¸æ“šè¼‰å…¥å’Œé è™•ç†é¡åˆ¥

# %%
class DataLoader:
    """æ•¸æ“šè¼‰å…¥å’Œé è™•ç†é¡åˆ¥"""
    
    def __init__(self, mmwave_base_path, ecg_base_path):
        self.mmwave_base_path = mmwave_base_path
        self.ecg_base_path = ecg_base_path
        self.distances = ['30cm', '45cm', '60cm', '90cm']
        
    def load_ecg_data(self, ecg_file_path):
        """è¼‰å…¥å–®å€‹ECGæª”æ¡ˆ"""
        try:
            ecg_df = pd.read_csv(ecg_file_path)
            
            if 'time' not in ecg_df.columns or 'ecg' not in ecg_df.columns:
                print(f"è­¦å‘Š: {ecg_file_path} ç¼ºå°‘å¿…è¦æ¬„ä½")
                return None, None
                
            df_cleaned = ecg_df.dropna(subset=['ecg'])
            ecg_signal = df_cleaned['ecg'].values
            timestamps_ns = df_cleaned['time'].values
            
            if len(timestamps_ns) < 2:
                return None, None
                
            # è½‰æ›ç‚ºç›¸å°æ™‚é–“ï¼ˆç§’ï¼‰
            times_s = timestamps_ns * 1e-9
            ecg_time = times_s - times_s[0]
            
            return ecg_signal, ecg_time
            
        except Exception as e:
            print(f"è¼‰å…¥ECGæ•¸æ“šéŒ¯èª¤: {ecg_file_path}, {e}")
            return None, None
    
    def load_mmwave_data(self, mmwave_file_path):
        """è¼‰å…¥å–®å€‹mmWaveæª”æ¡ˆ"""
        try:
            df = pd.read_csv(mmwave_file_path)
            
            if 'Heart_Waveform' not in df.columns:
                print(f"è­¦å‘Š: {mmwave_file_path} ç¼ºå°‘ Heart_Waveform æ¬„ä½")
                return None, None
                
            df_sorted = df.sort_values(by='Frame_Number')
            waveform_data = df_sorted['Heart_Waveform'].values
            
            # å‰µå»ºæ™‚é–“è»¸ (å‡è¨­å›ºå®šæ¡æ¨£ç‡ 11.11 Hz)
            fs = 11.11
            time_axis = np.arange(len(waveform_data)) / fs
            
            return waveform_data, time_axis
            
        except Exception as e:
            print(f"è¼‰å…¥mmWaveæ•¸æ“šéŒ¯èª¤: {mmwave_file_path}, {e}")
            return None, None
    
    def resample_signals(self, mmwave_signal, mmwave_time, ecg_signal, ecg_time, target_length=None):
        """é‡æ¡æ¨£ä¿¡è™Ÿåˆ°ç›¸åŒé•·åº¦"""
        try:
            # ç¢ºå®šç›®æ¨™é•·åº¦
            if target_length is None:
                target_length = min(len(mmwave_signal), len(ecg_signal))
            
            # é‡æ¡æ¨£åˆ°çµ±ä¸€æ™‚é–“è»¸
            if len(mmwave_time) > 1 and len(ecg_time) > 1:
                # å‰µå»ºçµ±ä¸€æ™‚é–“è»¸
                max_time = min(mmwave_time[-1], ecg_time[-1])
                unified_time = np.linspace(0, max_time, target_length)
                
                # é‡æ¡æ¨£ä¿¡è™Ÿ
                mmwave_resampled = np.interp(unified_time, mmwave_time, mmwave_signal)
                ecg_resampled = np.interp(unified_time, ecg_time, ecg_signal)
                
                return mmwave_resampled, ecg_resampled, unified_time
            else:
                return None, None, None
                
        except Exception as e:
            print(f"é‡æ¡æ¨£éŒ¯èª¤: {e}")
            return None, None, None
    
    def create_training_pairs(self, distance='45cm', max_pairs_per_distance=50):
        """å‰µå»ºè¨“ç·´æ•¸æ“šå°"""
        mmwave_folder = os.path.join(self.mmwave_base_path, distance)
        ecg_folder = os.path.join(self.ecg_base_path, distance)
        
        if not os.path.exists(mmwave_folder) or not os.path.exists(ecg_folder):
            print(f"è³‡æ–™å¤¾ä¸å­˜åœ¨: {mmwave_folder} æˆ– {ecg_folder}")
            return [], [], []
        
        # å–å¾—æª”æ¡ˆåˆ—è¡¨
        mmwave_files = sorted(glob.glob(os.path.join(mmwave_folder, "*.csv")))
        ecg_files = sorted(glob.glob(os.path.join(ecg_folder, "*.csv")))
        
        print(f"æ‰¾åˆ° mmWave æª”æ¡ˆ: {len(mmwave_files)} å€‹")
        print(f"æ‰¾åˆ° ECG æª”æ¡ˆ: {len(ecg_files)} å€‹")
        
        mmwave_data = []
        ecg_data = []
        timestamps = []
        
        # é™åˆ¶è™•ç†çš„æª”æ¡ˆæ•¸é‡ä»¥é¿å…è¨˜æ†¶é«”å•é¡Œ
        max_files = min(len(mmwave_files), len(ecg_files), max_pairs_per_distance)
        
        for i in range(max_files):
            mmwave_signal, mmwave_time = self.load_mmwave_data(mmwave_files[i])
            ecg_signal, ecg_time = self.load_ecg_data(ecg_files[i])
            
            if mmwave_signal is not None and ecg_signal is not None:
                # é‡æ¡æ¨£åˆ°ç›¸åŒé•·åº¦
                mmwave_resampled, ecg_resampled, unified_time = self.resample_signals(
                    mmwave_signal, mmwave_time, ecg_signal, ecg_time, target_length=600  # ç´„60ç§’çš„æ•¸æ“š
                )
                
                if mmwave_resampled is not None and ecg_resampled is not None:
                    mmwave_data.append(mmwave_resampled)
                    ecg_data.append(ecg_resampled)
                    timestamps.append(unified_time)
                    
                    if len(mmwave_data) % 10 == 0:
                        print(f"å·²è™•ç† {len(mmwave_data)} å°æ•¸æ“š...")
        
        print(f"æˆåŠŸå‰µå»º {len(mmwave_data)} å°è¨“ç·´æ•¸æ“š ({distance})")
        return mmwave_data, ecg_data, timestamps

# %% [markdown]
# ## 2. æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨æ¨¡å‹

# %%
class DeepAdaptiveFilterModel:
    """æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨æ¨¡å‹"""
    
    def __init__(self, input_window_size=64, model_type='hybrid'):
        self.input_window_size = input_window_size
        self.model_type = model_type  # 'cnn', 'lstm', 'hybrid', 'transformer'
        self.model = None
        self.scaler_input = StandardScaler()
        self.scaler_output = StandardScaler()
        self.is_fitted = False
        
    def build_cnn_model(self):
        """å»ºæ§‹CNNæ¨¡å‹"""
        model = Sequential([
            Input(shape=(self.input_window_size, 1)),
            Conv1D(64, kernel_size=5, activation='relu', padding='same'),
            MaxPooling1D(pool_size=2),
            Conv1D(128, kernel_size=3, activation='relu', padding='same'),
            MaxPooling1D(pool_size=2),
            Conv1D(64, kernel_size=3, activation='relu', padding='same'),
            Flatten(),
            Dense(128, activation='relu'),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dropout(0.2),
            Dense(1, activation='linear')
        ])
        return model
    
    def build_lstm_model(self):
        """å»ºæ§‹LSTMæ¨¡å‹"""
        model = Sequential([
            Input(shape=(self.input_window_size, 1)),
            LSTM(128, return_sequences=True),
            Dropout(0.3),
            LSTM(64, return_sequences=False),
            Dropout(0.2),
            Dense(64, activation='relu'),
            Dense(32, activation='relu'),
            Dense(1, activation='linear')
        ])
        return model
    
    def build_hybrid_model(self):
        """å»ºæ§‹æ··åˆCNN-LSTMæ¨¡å‹"""
        input_layer = Input(shape=(self.input_window_size, 1))
        
        # CNN åˆ†æ”¯
        cnn_branch = Conv1D(64, kernel_size=5, activation='relu', padding='same')(input_layer)
        cnn_branch = MaxPooling1D(pool_size=2)(cnn_branch)
        cnn_branch = Conv1D(32, kernel_size=3, activation='relu', padding='same')(cnn_branch)
        
        # LSTM åˆ†æ”¯
        lstm_branch = LSTM(64, return_sequences=True)(input_layer)
        lstm_branch = LSTM(32, return_sequences=False)(lstm_branch)
        
        # åˆä½µåˆ†æ”¯
        merged = layers.concatenate([Flatten()(cnn_branch), lstm_branch])
        
        # å…¨é€£æ¥å±¤
        dense_layer = Dense(128, activation='relu')(merged)
        dense_layer = Dropout(0.3)(dense_layer)
        dense_layer = Dense(64, activation='relu')(dense_layer)
        dense_layer = Dropout(0.2)(dense_layer)
        output_layer = Dense(1, activation='linear')(dense_layer)
        
        model = Model(inputs=input_layer, outputs=output_layer)
        return model
    
    def build_transformer_model(self):
        """å»ºæ§‹Transformeræ¨¡å‹"""
        def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
            # Multi-head self-attention
            attention_layer = layers.MultiHeadAttention(
                key_dim=head_size, num_heads=num_heads, dropout=dropout
            )
            attention_output = attention_layer(inputs, inputs)
            attention_output = layers.Dropout(dropout)(attention_output)
            attention_output = layers.LayerNormalization(epsilon=1e-6)(inputs + attention_output)
            
            # Feed-forward network
            ffn = Sequential([
                Dense(ff_dim, activation='relu'),
                Dense(inputs.shape[-1])
            ])
            ffn_output = ffn(attention_output)
            ffn_output = layers.Dropout(dropout)(ffn_output)
            return layers.LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)
        
        inputs = Input(shape=(self.input_window_size, 1))
        
        # ä½ç½®ç·¨ç¢¼
        x = layers.Dense(64)(inputs)
        
        # Transformer ç·¨ç¢¼å™¨
        x = transformer_encoder(x, head_size=16, num_heads=4, ff_dim=128, dropout=0.1)
        x = transformer_encoder(x, head_size=16, num_heads=4, ff_dim=128, dropout=0.1)
        
        # å…¨åŸŸå¹³å‡æ± åŒ–å’Œè¼¸å‡º
        x = layers.GlobalAveragePooling1D()(x)
        x = layers.Dropout(0.1)(x)
        x = layers.Dense(64, activation='relu')(x)
        outputs = layers.Dense(1, activation='linear')(x)
        
        model = Model(inputs, outputs)
        return model
    
    def build_model(self):
        """æ ¹æ“šæ¨¡å‹é¡å‹å»ºæ§‹æ¨¡å‹"""
        if self.model_type == 'cnn':
            model = self.build_cnn_model()
        elif self.model_type == 'lstm':
            model = self.build_lstm_model()
        elif self.model_type == 'hybrid':
            model = self.build_hybrid_model()
        elif self.model_type == 'transformer':
            model = self.build_transformer_model()
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {self.model_type}")
        
        # ç·¨è­¯æ¨¡å‹
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae', 'mse']
        )
        
        return model
    
    def prepare_training_data(self, mmwave_signals, ecg_signals):
        """æº–å‚™è¨“ç·´æ•¸æ“š"""
        X_sequences = []
        y_sequences = []
        
        print("æ­£åœ¨æº–å‚™è¨“ç·´æ•¸æ“š...")
        
        for i, (mmwave_signal, ecg_signal) in enumerate(zip(mmwave_signals, ecg_signals)):
            # æ­£è¦åŒ–ä¿¡è™Ÿ
            mmwave_norm = (mmwave_signal - np.mean(mmwave_signal)) / np.std(mmwave_signal)
            ecg_norm = (ecg_signal - np.mean(ecg_signal)) / np.std(ecg_signal)
            
            # å‰µå»ºæ»‘å‹•çª—å£
            for j in range(len(mmwave_norm) - self.input_window_size):
                X_sequences.append(mmwave_norm[j:j + self.input_window_size])
                y_sequences.append(ecg_norm[j + self.input_window_size])
            
            if (i + 1) % 10 == 0:
                print(f"å·²è™•ç† {i + 1}/{len(mmwave_signals)} å€‹ä¿¡è™Ÿ...")
        
        X = np.array(X_sequences)
        y = np.array(y_sequences)
        
        # é‡å¡‘ç‚º (samples, time_steps, features)
        X = X.reshape(X.shape[0], X.shape[1], 1)
        
        print(f"è¨“ç·´æ•¸æ“šå½¢ç‹€: X={X.shape}, y={y.shape}")
        
        return X, y
    
    def train(self, mmwave_signals, ecg_signals, validation_split=0.2, epochs=100, batch_size=32, save_path=None):
        """è¨“ç·´æ¨¡å‹"""
        print(f"é–‹å§‹è¨“ç·´æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ ({self.model_type} æ¨¡å‹)...")
        
        # æº–å‚™è¨“ç·´æ•¸æ“š
        X, y = self.prepare_training_data(mmwave_signals, ecg_signals)
        
        # åˆ†å‰²è¨“ç·´å’Œé©—è­‰æ•¸æ“š
        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)
        
        print(f"è¨“ç·´é›†å¤§å°: {X_train.shape[0]} æ¨£æœ¬")
        print(f"é©—è­‰é›†å¤§å°: {X_val.shape[0]} æ¨£æœ¬")
        
        # å»ºæ§‹æ¨¡å‹
        self.model = self.build_model()
        
        # é¡¯ç¤ºæ¨¡å‹æ¶æ§‹
        print("\næ¨¡å‹æ¶æ§‹:")
        self.model.summary()
        
        # è¨­å®šå›èª¿å‡½æ•¸
        callback_list = [
            callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),
            callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-7),
        ]
        
        if save_path:
            checkpoint_callback = callbacks.ModelCheckpoint(
                filepath=save_path + '_checkpoint.h5',
                monitor='val_loss',
                save_best_only=True,
                save_weights_only=False
            )
            callback_list.append(checkpoint_callback)
        
        # è¨“ç·´æ¨¡å‹
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callback_list,
            verbose=1
        )
        
        self.is_fitted = True
        
        # ä¿å­˜æ¨¡å‹å’Œè¨“ç·´æ­·å²
        if save_path:
            self.model.save(save_path + '.h5')
            
            # ä¿å­˜è¨“ç·´æ­·å²
            with open(save_path + '_history.pkl', 'wb') as f:
                pickle.dump(history.history, f)
            
            print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}.h5")
            print(f"è¨“ç·´æ­·å²å·²ä¿å­˜åˆ°: {save_path}_history.pkl")
        
        return history
    
    def filter_signal(self, input_signal):
        """ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹æ¿¾æ³¢ä¿¡è™Ÿ"""
        if not self.is_fitted or self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´æˆ–è¼‰å…¥")
        
        # æ­£è¦åŒ–è¼¸å…¥ä¿¡è™Ÿ
        input_norm = (input_signal - np.mean(input_signal)) / np.std(input_signal)
        
        # æº–å‚™é æ¸¬æ•¸æ“š
        X_pred = []
        for i in range(len(input_norm) - self.input_window_size):
            X_pred.append(input_norm[i:i + self.input_window_size])
        
        X_pred = np.array(X_pred).reshape(-1, self.input_window_size, 1)
        
        # é æ¸¬
        predictions = self.model.predict(X_pred, verbose=0)
        
        # çµ„åˆè¼¸å‡ºä¿¡è™Ÿ
        output_signal = np.zeros(len(input_signal))
        output_signal[:self.input_window_size] = input_norm[:self.input_window_size]
        output_signal[self.input_window_size:] = predictions.flatten()
        
        return output_signal

# %% [markdown]
# ## 3. è¨“ç·´ç®¡ç†å™¨

# %%
class TrainingManager:
    """è¨“ç·´ç®¡ç†å™¨"""
    
    def __init__(self, mmwave_base_path, ecg_base_path):
        self.data_loader = DataLoader(mmwave_base_path, ecg_base_path)
        self.models = {}
        
    def train_all_models(self, distances=['45cm'], model_types=['hybrid'], 
                        max_pairs_per_distance=30, epochs=50, save_dir='models'):
        """è¨“ç·´æ‰€æœ‰æ¨¡å‹çµ„åˆ"""
        
        # å‰µå»ºæ¨¡å‹ä¿å­˜ç›®éŒ„
        os.makedirs(save_dir, exist_ok=True)
        
        results = {}
        
        for distance in distances:
            print(f"\n{'='*80}")
            print(f"è™•ç†è·é›¢: {distance}")
            print(f"{'='*80}")
            
            # è¼‰å…¥æ•¸æ“š
            mmwave_data, ecg_data, timestamps = self.data_loader.create_training_pairs(
                distance=distance, 
                max_pairs_per_distance=max_pairs_per_distance
            )
            
            if len(mmwave_data) == 0:
                print(f"è­¦å‘Š: {distance} æ²’æœ‰å¯ç”¨çš„è¨“ç·´æ•¸æ“š")
                continue
            
            for model_type in model_types:
                print(f"\nè¨“ç·´ {model_type} æ¨¡å‹ ({distance})...")
                
                # å‰µå»ºæ¨¡å‹
                model = DeepAdaptiveFilterModel(
                    input_window_size=64, 
                    model_type=model_type
                )
                
                # è¨­å®šä¿å­˜è·¯å¾‘
                save_path = os.path.join(save_dir, f'daf_{model_type}_{distance.replace("cm", "")}cm')
                
                try:
                    # è¨“ç·´æ¨¡å‹
                    history = model.train(
                        mmwave_signals=mmwave_data,
                        ecg_signals=ecg_data,
                        validation_split=0.2,
                        epochs=epochs,
                        batch_size=32,
                        save_path=save_path
                    )
                    
                    # ä¿å­˜æ¨¡å‹å¯¦ä¾‹
                    model_key = f"{distance}_{model_type}"
                    self.models[model_key] = model
                    results[model_key] = {
                        'model': model,
                        'history': history.history,
                        'save_path': save_path + '.h5'
                    }
                    
                    print(f"âœ… {model_type} æ¨¡å‹ ({distance}) è¨“ç·´å®Œæˆ")
                    
                except Exception as e:
                    print(f"âŒ {model_type} æ¨¡å‹ ({distance}) è¨“ç·´å¤±æ•—: {e}")
                    continue
        
        return results
    
    def plot_training_history(self, results, save_path='training_history.png'):
        """ç¹ªè£½è¨“ç·´æ­·å²"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨è¨“ç·´æ­·å²', fontsize=16, fontweight='bold')
        
        colors = ['blue', 'red', 'green', 'orange', 'purple']
        
        for i, (model_key, result) in enumerate(results.items()):
            history = result['history']
            color = colors[i % len(colors)]
            
            # Loss
            axes[0, 0].plot(history['loss'], color=color, label=f'{model_key} - è¨“ç·´')
            axes[0, 0].plot(history['val_loss'], color=color, linestyle='--', label=f'{model_key} - é©—è­‰')
            axes[0, 0].set_title('è¨“ç·´æå¤±')
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss (MSE)')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # MAE
            axes[0, 1].plot(history['mae'], color=color, label=f'{model_key} - è¨“ç·´')
            axes[0, 1].plot(history['val_mae'], color=color, linestyle='--', label=f'{model_key} - é©—è­‰')
            axes[0, 1].set_title('å¹³å‡çµ•å°èª¤å·®')
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('MAE')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        
        # éš±è—æœªä½¿ç”¨çš„å­åœ–
        axes[1, 0].axis('off')
        axes[1, 1].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"è¨“ç·´æ­·å²åœ–è¡¨å·²ä¿å­˜: {save_path}")
        plt.show()
        plt.close()

# %% [markdown]
# ## 4. ä¸»ç¨‹å¼

# %%
def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    print("ğŸš€ æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨è¨“ç·´ç¨‹å¼")
    print("="*80)
    
    # è¨­å®šè·¯å¾‘
    mmwave_base_path = r"C:\Users\jk121\Documents\Code\mmWave-PAPER\Output\merged_csv"
    ecg_base_path = r"C:\Users\jk121\Documents\Code\mmWave-PAPER\Output\ECG Data\CSV"
    
    print(f"mmWave æ•¸æ“šè·¯å¾‘: {mmwave_base_path}")
    print(f"ECG æ•¸æ“šè·¯å¾‘: {ecg_base_path}")
    
    # æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(mmwave_base_path):
        print(f"âŒ mmWave æ•¸æ“šè·¯å¾‘ä¸å­˜åœ¨: {mmwave_base_path}")
        return
    
    if not os.path.exists(ecg_base_path):
        print(f"âŒ ECG æ•¸æ“šè·¯å¾‘ä¸å­˜åœ¨: {ecg_base_path}")
        return
    
    # å‰µå»ºè¨“ç·´ç®¡ç†å™¨
    trainer = TrainingManager(mmwave_base_path, ecg_base_path)
    
    # è¨­å®šè¨“ç·´åƒæ•¸
    distances = ['30cm', '45cm', '60cm', '90cm']  # å¯ä»¥é¸æ“‡ç‰¹å®šè·é›¢
    model_types = ['hybrid', 'cnn', 'lstm']       # å¯ä»¥é¸æ“‡ç‰¹å®šæ¨¡å‹é¡å‹
    max_pairs_per_distance = 20                    # æ¯å€‹è·é›¢æœ€å¤šä½¿ç”¨çš„æª”æ¡ˆæ•¸
    epochs = 50                                    # è¨“ç·´è¼ªæ•¸
    
    print(f"\nè¨“ç·´è¨­å®š:")
    print(f"  è·é›¢: {distances}")
    print(f"  æ¨¡å‹é¡å‹: {model_types}")
    print(f"  æ¯è·é›¢æœ€å¤§æª”æ¡ˆæ•¸: {max_pairs_per_distance}")
    print(f"  è¨“ç·´è¼ªæ•¸: {epochs}")
    
    # é–‹å§‹è¨“ç·´
    print(f"\né–‹å§‹æ‰¹æ¬¡è¨“ç·´...")
    results = trainer.train_all_models(
        distances=distances,
        model_types=model_types,
        max_pairs_per_distance=max_pairs_per_distance,
        epochs=epochs,
        save_dir='mmWave_heart_amplitude/code/trained_models'
    )
    
    # ç¹ªè£½è¨“ç·´æ­·å²
    if results:
        trainer.plot_training_history(results, 'mmWave_heart_amplitude/code/training_history.png')
        
        print(f"\nğŸ‰ è¨“ç·´å®Œæˆ!")
        print(f"è¨“ç·´çµæœç¸½çµ:")
        for model_key, result in results.items():
            print(f"  âœ… {model_key}: {result['save_path']}")
            
        print(f"\nğŸ“‹ ä½¿ç”¨èªªæ˜:")
        print(f"  1. è¨“ç·´å¥½çš„æ¨¡å‹å·²ä¿å­˜åœ¨ 'mmWave_heart_amplitude/code/trained_models/' ç›®éŒ„")
        print(f"  2. å¯ä»¥åœ¨ adaptive_filters_comparison.py ä¸­è¼‰å…¥é€™äº›æ¨¡å‹")
        print(f"  3. è¨“ç·´æ­·å²åœ–è¡¨: mmWave_heart_amplitude/code/training_history.png")
        
    else:
        print("âŒ æ²’æœ‰æˆåŠŸè¨“ç·´ä»»ä½•æ¨¡å‹")

# å¿«é€Ÿè¨“ç·´å‡½æ•¸ï¼ˆåƒ…é‡å°ç‰¹å®šé…ç½®ï¼‰
def quick_train():
    """å¿«é€Ÿè¨“ç·´å‡½æ•¸ - åƒ…è¨“ç·´45cmçš„hybridæ¨¡å‹"""
    print("ğŸš€ å¿«é€Ÿè¨“ç·´æ¨¡å¼ - åƒ…è¨“ç·´ 45cm hybrid æ¨¡å‹")
    print("="*50)
    
    # è¨­å®šè·¯å¾‘
    mmwave_base_path = r"C:\Users\jk121\Documents\Code\mmWave-PAPER\Output\merged_csv"
    ecg_base_path = r"C:\Users\jk121\Documents\Code\mmWave-PAPER\Output\ECG Data\CSV"
    
    # å‰µå»ºè¨“ç·´ç®¡ç†å™¨
    trainer = TrainingManager(mmwave_base_path, ecg_base_path)
    
    # å¿«é€Ÿè¨“ç·´è¨­å®š
    results = trainer.train_all_models(
        distances=['45cm'],
        model_types=['hybrid'],
        max_pairs_per_distance=15,
        epochs=30,
        save_dir='mmWave_heart_amplitude/code/trained_models'
    )
    
    if results:
        print("âœ… å¿«é€Ÿè¨“ç·´å®Œæˆ!")
        for model_key, result in results.items():
            print(f"  æ¨¡å‹ä¿å­˜è·¯å¾‘: {result['save_path']}")
    else:
        print("âŒ å¿«é€Ÿè¨“ç·´å¤±æ•—")

# %%
if __name__ == "__main__":
    # é¸æ“‡é‹è¡Œæ¨¡å¼
    print("é¸æ“‡é‹è¡Œæ¨¡å¼:")
    print("1. å®Œæ•´è¨“ç·´ (æ‰€æœ‰è·é›¢å’Œæ¨¡å‹é¡å‹)")
    print("2. å¿«é€Ÿè¨“ç·´ (åƒ…45cm hybridæ¨¡å‹)")
    
    choice = input("è«‹è¼¸å…¥é¸é … (1 æˆ– 2ï¼Œé è¨­ç‚º 2): ").strip() or "2"
    
    if choice == "1":
        main()
    else:
        quick_train()
