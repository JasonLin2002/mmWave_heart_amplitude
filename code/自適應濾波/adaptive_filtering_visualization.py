# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
import pywt
from scipy import linalg
import os
from sklearn.preprocessing import StandardScaler
from scipy.stats import spearmanr
from dtaidistance import dtw
from scipy.signal import coherence
from scipy.stats import entropy
import tensorflow as tf
from tensorflow import keras

# %% [markdown]
# ## 1. æ•¸æ“šè¼‰å…¥å’Œé è™•ç†å‡½æ•¸

# %%
def load_ecg_data(ecg_path):
    """Load and preprocess ECG data (last 60 seconds)."""
    print(f"Loading ECG data from: {ecg_path}")
    
    try:
        ecg_df = pd.read_csv(ecg_path)
        print(f"ECG data shape: {ecg_df.shape}")
        print("\nECG data columns:")
        print(ecg_df.columns.tolist())
        
        # æª¢æŸ¥å¿…è¦çš„æ¬„ä½æ˜¯å¦å­˜åœ¨
        if 'time' not in ecg_df.columns or 'ecg' not in ecg_df.columns:
            print("éŒ¯èª¤: ECG CSV æª”æ¡ˆä¸­ç¼ºå°‘ 'time' æˆ– 'ecg' æ¬„ä½ã€‚")
            return None, None, None
            
        # ç§»é™¤ 'ecg' æ¬„ä½ä¸­ NaN çš„è¡Œï¼Œä¸¦ç¢ºä¿ 'time' ä¹Ÿç›¸æ‡‰ç§»é™¤
        df_cleaned = ecg_df.dropna(subset=['ecg'])
        
        ecg_signal = df_cleaned['ecg'].values
        timestamps_ns = df_cleaned['time'].values  # æ™‚é–“æˆ³ï¼ˆå¥ˆç§’ï¼‰
        
        if len(timestamps_ns) < 2:
            print("éŒ¯èª¤: ECG æ•¸æ“šä¸è¶³ä»¥è¨ˆç®—æ¡æ¨£ç‡ã€‚")
            return None, None, None
        
        # ECGæ¡æ¨£ç‡ç‚º130Hz
        ecg_fs = 130.0
        print(f"ECG è¨­å®šæ¡æ¨£ç‡: {ecg_fs:.2f} Hz")
        
        # è½‰æ›æ™‚é–“æˆ³ç‚ºç§’ä¸¦å–æœ€å¾Œ60ç§’
        times_s = timestamps_ns * 1e-9
        N = len(ecg_signal)
        total_duration = times_s[-1] - times_s[0] if N > 1 else 0
        display_duration = 60.0
        
        if total_duration <= display_duration:
            start_idx = 0
            end_idx = N
        else:
            end_time = times_s[-1]
            start_time = end_time - display_duration
            start_idx = np.searchsorted(times_s, start_time, side="left")
            end_idx = N
            
        # å–æœ€å¾Œ60ç§’çš„æ•¸æ“š
        ecg_signal = ecg_signal[start_idx:end_idx]
        timestamps_ns = timestamps_ns[start_idx:end_idx]
        times_s = times_s[start_idx:end_idx]
        
        # å‰µå»ºç›¸å°æ™‚é–“è»¸ï¼ˆå¾0é–‹å§‹ï¼‰
        ecg_time = times_s - times_s[0]
        
        print(f"ECG signal length: {len(ecg_signal)} samples ({len(ecg_signal)/ecg_fs:.1f} seconds)")
        print(f"ECG time range: {ecg_time[0]:.1f} to {ecg_time[-1]:.1f} seconds")
        
        return ecg_signal, ecg_time, ecg_fs
        
    except Exception as e:
        print(f"Error loading ECG data: {e}")
        return None, None, None

def load_and_preprocess_data(file_path):
    """Read and preprocess radar heart amplitude data (only last 60 seconds)."""
    print(f"Reading file: {file_path}")
    df = pd.read_csv(file_path)
    print(f"Data shape: {df.shape}")
    print("\nData preview:")
    print(df.head())
    fs = 11.11  # Fixed sampling rate
    print(f"\nEstimated sampling rate: {fs:.2f} Hz")
    df_sorted = df.sort_values(by='Frame_Number')
    waveform_data = df_sorted['Heart_Waveform'].values
    timestamps = df_sorted['Timestamp'].values
    heart_rates = df_sorted['Heart_Rate'].values
    frame_numbers = df_sorted['Frame_Number'].values

    # Only keep last 60 seconds
    N = len(waveform_data)
    time_axis_full = np.arange(N) / fs
    total_duration = time_axis_full[-1] if N > 1 else 0
    display_duration = 60.0
    if total_duration <= display_duration:
        start_idx = 0
        end_idx = N
    else:
        end_time = time_axis_full[-1]
        start_time = end_time - display_duration
        start_idx = np.searchsorted(time_axis_full, start_time, side="left")
        end_idx = N
    waveform_data = waveform_data[start_idx:end_idx]
    timestamps = timestamps[start_idx:end_idx]
    heart_rates = heart_rates[start_idx:end_idx]
    frame_numbers = frame_numbers[start_idx:end_idx]
    return waveform_data, timestamps, heart_rates, frame_numbers, fs

# %% [markdown]
# ## 2. è‡ªé©æ‡‰æ¿¾æ³¢å™¨å¯¦ç¾

# %%
class LMSFilter:
    """æœ€å°å‡æ–¹ (LMS) è‡ªé©æ‡‰æ¿¾æ³¢å™¨"""
    
    def __init__(self, n_taps=32, mu=0.01):
        self.n_taps = n_taps
        self.mu = mu
        self.weights = np.zeros(n_taps)
        self.buffer = np.zeros(n_taps)
        
    def filter(self, input_signal, desired_signal):
        """æ‡‰ç”¨LMSæ¿¾æ³¢"""
        output = []
        error_history = []
        
        for i in range(len(input_signal)):
            # æ›´æ–°è¼¸å…¥ç·©è¡å€
            self.buffer = np.roll(self.buffer, -1)
            self.buffer[-1] = input_signal[i]
            
            # è¨ˆç®—è¼¸å‡º
            y = np.dot(self.weights, self.buffer)
            output.append(y)
            
            # è¨ˆç®—èª¤å·®
            if i < len(desired_signal):
                error = desired_signal[i] - y
                error_history.append(error)
                
                # æ›´æ–°æ¬Šé‡
                self.weights += self.mu * error * self.buffer
            else:
                error_history.append(0)
        
        return np.array(output), np.array(error_history)

class RLSFilter:
    """éæ­¸æœ€å°äºŒä¹˜ (RLS) è‡ªé©æ‡‰æ¿¾æ³¢å™¨"""
    
    def __init__(self, n_taps=32, forgetting_factor=0.99, reg_param=1e-4):
        self.n_taps = n_taps
        self.lam = forgetting_factor
        self.weights = np.zeros(n_taps)
        self.P = np.eye(n_taps) / reg_param
        self.buffer = np.zeros(n_taps)
        
    def filter(self, input_signal, desired_signal):
        """æ‡‰ç”¨RLSæ¿¾æ³¢"""
        output = []
        error_history = []
        
        for i in range(len(input_signal)):
            # æ›´æ–°è¼¸å…¥ç·©è¡å€
            self.buffer = np.roll(self.buffer, -1)
            self.buffer[-1] = input_signal[i]
            
            # è¨ˆç®—è¼¸å‡º
            y = np.dot(self.weights, self.buffer)
            output.append(y)
            
            # è¨ˆç®—èª¤å·®ä¸¦æ›´æ–°æ¬Šé‡
            if i < len(desired_signal):
                error = desired_signal[i] - y
                error_history.append(error)
                
                # RLSæ¬Šé‡æ›´æ–°
                k = (self.P @ self.buffer) / (self.lam + self.buffer.T @ self.P @ self.buffer)
                self.P = (self.P - np.outer(k, self.buffer.T @ self.P)) / self.lam
                self.weights += k * error
            else:
                error_history.append(0)
                
        return np.array(output), np.array(error_history)

class NLMSFilter:
    """æ­£è¦åŒ–LMS (NLMS) è‡ªé©æ‡‰æ¿¾æ³¢å™¨"""
    
    def __init__(self, n_taps=32, mu=0.5, eps=1e-8):
        self.n_taps = n_taps
        self.mu = mu
        self.eps = eps
        self.weights = np.zeros(n_taps)
        self.buffer = np.zeros(n_taps)
        
    def filter(self, input_signal, desired_signal):
        """æ‡‰ç”¨NLMSæ¿¾æ³¢"""
        output = []
        error_history = []
        
        for i in range(len(input_signal)):
            # æ›´æ–°è¼¸å…¥ç·©è¡å€
            self.buffer = np.roll(self.buffer, -1)
            self.buffer[-1] = input_signal[i]
            
            # è¨ˆç®—è¼¸å‡º
            y = np.dot(self.weights, self.buffer)
            output.append(y)
            
            # è¨ˆç®—èª¤å·®
            if i < len(desired_signal):
                error = desired_signal[i] - y
                error_history.append(error)
                
                # NLMSæ¬Šé‡æ›´æ–° (æ­£è¦åŒ–æ­¥é•·)
                norm_factor = np.dot(self.buffer, self.buffer) + self.eps
                self.weights += (self.mu * error / norm_factor) * self.buffer
            else:
                error_history.append(0)
                
        return np.array(output), np.array(error_history)

class DeepAdaptiveFilter:
    """æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (DAF)"""
    
    def __init__(self, input_dim=64, model_path=None, model_type='cnn'):
        self.input_dim = input_dim
        self.model_type = model_type
        self.model = None
        
        if model_path and os.path.exists(model_path):
            try:
                # å˜—è©¦å¤šç¨®è¼‰å…¥æ–¹å¼ä¾†è§£æ±ºåºåˆ—åŒ–å•é¡Œ
                print(f"ğŸ”„ æ­£åœ¨è¼‰å…¥ {model_type.upper()} æ¨¡å‹: {model_path}")
                
                # æ–¹æ³•1ï¼šä½¿ç”¨ compile=False ä¾†é¿å…ç·¨è­¯ç›¸é—œçš„åºåˆ—åŒ–å•é¡Œ
                try:
                    self.model = tf.keras.models.load_model(model_path, compile=False)
                    # æ‰‹å‹•é‡æ–°ç·¨è­¯æ¨¡å‹
                    self.model.compile(optimizer='adam', loss='mse', metrics=['mae'])
                    print(f"âœ… æˆåŠŸè¼‰å…¥æ‚¨è¨“ç·´çš„ {model_type.upper()} æ¨¡å‹ (æ–¹æ³•1)")
                except Exception as e1:
                    print(f"ğŸ”„ æ–¹æ³•1å¤±æ•—: {e1}")
                    
                    # æ–¹æ³•2ï¼šä½¿ç”¨ custom_objects ä¾†è¨»å†Šè‡ªå®šç¾©å‡½æ•¸
                    try:
                        custom_objects = {
                            'mse': tf.keras.losses.MeanSquaredError(),
                            'mae': tf.keras.metrics.MeanAbsoluteError(),
                            'mean_squared_error': tf.keras.losses.MeanSquaredError(),
                            'mean_absolute_error': tf.keras.metrics.MeanAbsoluteError()
                        }
                        self.model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)
                        print(f"âœ… æˆåŠŸè¼‰å…¥æ‚¨è¨“ç·´çš„ {model_type.upper()} æ¨¡å‹ (æ–¹æ³•2)")
                    except Exception as e2:
                        print(f"ğŸ”„ æ–¹æ³•2å¤±æ•—: {e2}")
                        
                        # æ–¹æ³•3ï¼šè¼‰å…¥æ¬Šé‡è€Œéå®Œæ•´æ¨¡å‹
                        try:
                            self.model = self._create_architecture_model()
                            self.model.load_weights(model_path.replace('.h5', '_weights.h5'))
                            print(f"âœ… æˆåŠŸè¼‰å…¥æ‚¨è¨“ç·´çš„ {model_type.upper()} æ¨¡å‹æ¬Šé‡ (æ–¹æ³•3)")
                        except Exception as e3:
                            print(f"ğŸ”„ æ–¹æ³•3å¤±æ•—: {e3}")
                            print(f"âš ï¸ æ‰€æœ‰è¼‰å…¥æ–¹æ³•éƒ½å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ¨¡å‹")
                            self.model = self._create_fallback_model()
                            
            except Exception as e:
                print(f"âŒ è¼‰å…¥ {model_type.upper()} æ¨¡å‹æ™‚ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e}")
                self.model = self._create_fallback_model()
        else:
            print(f"âš ï¸ {model_type.upper()} æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
            self.model = self._create_fallback_model()
    
    def _create_architecture_model(self):
        """å‰µå»ºèˆ‡è¨“ç·´æ¨¡å‹ç›¸åŒæ¶æ§‹çš„æ¨¡å‹"""
        try:
            if self.model_type == 'cnn':
                model = tf.keras.Sequential([
                    tf.keras.layers.Conv1D(32, 3, activation='relu', input_shape=(self.input_dim, 1)),
                    tf.keras.layers.Conv1D(64, 3, activation='relu'),
                    tf.keras.layers.GlobalMaxPooling1D(),
                    tf.keras.layers.Dense(50, activation='relu'),
                    tf.keras.layers.Dense(1, activation='linear')
                ])
            elif self.model_type == 'lstm':
                model = tf.keras.Sequential([
                    tf.keras.layers.LSTM(50, input_shape=(self.input_dim, 1), return_sequences=True),
                    tf.keras.layers.LSTM(50),
                    tf.keras.layers.Dense(25, activation='relu'),
                    tf.keras.layers.Dense(1, activation='linear')
                ])
            else:  # hybrid
                model = tf.keras.Sequential([
                    tf.keras.layers.Conv1D(32, 3, activation='relu', input_shape=(self.input_dim, 1)),
                    tf.keras.layers.LSTM(50),
                    tf.keras.layers.Dense(25, activation='relu'),
                    tf.keras.layers.Dense(1, activation='linear')
                ])
            
            model.compile(optimizer='adam', loss='mse', metrics=['mae'])
            return model
        except Exception as e:
            print(f"âŒ å‰µå»ºæ¶æ§‹æ¨¡å‹å¤±æ•—: {e}")
            return None

    def _create_fallback_model(self):
        """å‰µå»ºå‚™ç”¨æ¨¡å‹ï¼ˆç•¶æ‰€æœ‰è¼‰å…¥æ–¹æ³•éƒ½å¤±æ•—æ™‚ä½¿ç”¨ï¼‰"""
        try:
            model = self._create_architecture_model()
            if model is not None:
                print(f"âš ï¸ ä½¿ç”¨æœªè¨“ç·´çš„å‚™ç”¨ {self.model_type.upper()} æ¨¡å‹")
            return model
        except Exception as e:
            print(f"âŒ å‰µå»ºå‚™ç”¨æ¨¡å‹å¤±æ•—: {e}")
            return None
    
    def filter(self, input_signal):
        """æ‡‰ç”¨æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢"""
        if self.model is None:
            print(f"âŒ {self.model_type.upper()} æ¨¡å‹æœªè¼‰å…¥ï¼Œè¿”å›åŸå§‹ä¿¡è™Ÿ")
            return input_signal
        
        try:
            # æ¨™æº–åŒ–è¼¸å…¥ä¿¡è™Ÿ
            scaler = StandardScaler()
            signal_scaled = scaler.fit_transform(input_signal.reshape(-1, 1)).flatten()
            
            # å‰µå»ºæ»‘å‹•çª—å£
            windows = []
            for i in range(len(signal_scaled) - self.input_dim + 1):
                windows.append(signal_scaled[i:i + self.input_dim])
            
            if len(windows) == 0:
                print(f"âš ï¸ ä¿¡è™Ÿé•·åº¦ä¸è¶³ï¼Œç„¡æ³•å‰µå»ºçª—å£")
                return input_signal
                
            X = np.array(windows).reshape(len(windows), self.input_dim, 1)
            
            # é æ¸¬
            predictions = self.model.predict(X, verbose=0)
            
            # é‡å»ºå®Œæ•´ä¿¡è™Ÿé•·åº¦
            output = np.zeros(len(input_signal))
            output[:self.input_dim-1] = signal_scaled[:self.input_dim-1]  # å¡«å……å‰é¢éƒ¨åˆ†
            output[self.input_dim-1:] = predictions.flatten()
            
            # åæ¨™æº–åŒ–
            output_rescaled = scaler.inverse_transform(output.reshape(-1, 1)).flatten()
            
            print(f"âœ… {self.model_type.upper()} æ¿¾æ³¢å®Œæˆï¼Œè™•ç† {len(input_signal)} å€‹æ¨£æœ¬")
            return output_rescaled
            
        except Exception as e:
            print(f"âŒ {self.model_type.upper()} æ¿¾æ³¢è™•ç†å¤±æ•—: {e}")
            return input_signal

# %% [markdown]
# ## 3. è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å‡½æ•¸

# %%
def process_adaptive_filtering_methods(waveform_data, fs, distance='45cm'):
    """
    è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è™•ç†
    
    è™•ç†æµç¨‹ï¼š
    1. åŸå§‹è¨Šè™Ÿ
    2. LMS è‡ªé©æ‡‰æ¿¾æ³¢
    3. RLS è‡ªé©æ‡‰æ¿¾æ³¢  
    4. NLMS è‡ªé©æ‡‰æ¿¾æ³¢
    5. DAF-CNN æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    6. DAF-LSTM æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    7. DAF-Hybrid æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    """
    
    results = {}
    
    print("ğŸ”„ é–‹å§‹è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†...")
    
    # 1. åŸå§‹è¨Šè™Ÿ
    results['1_raw'] = waveform_data
    print("âœ… 1. åŸå§‹è¨Šè™Ÿ")
    
    # å‰è™•ç†ï¼šå»è¶¨å‹¢å’Œæ¨™æº–åŒ–
    detrended = signal.detrend(waveform_data)
    scaler = StandardScaler()
    normalized = scaler.fit_transform(detrended.reshape(-1, 1)).flatten()
    
    # å‰µå»ºæœŸæœ›ä¿¡è™Ÿï¼ˆä½¿ç”¨è¼•å¾®çš„ä½é€šæ¿¾æ³¢ä½œç‚ºåƒè€ƒï¼‰
    try:
        b, a = signal.butter(4, 0.3, btype='lowpass')
        desired_signal = signal.filtfilt(b, a, normalized)
    except:
        desired_signal = normalized
    
    # 2. LMS è‡ªé©æ‡‰æ¿¾æ³¢
    try:
        lms_filter = LMSFilter(n_taps=32, mu=0.01)
        lms_output, lms_error = lms_filter.filter(normalized, desired_signal)
        results['2_lms'] = scaler.inverse_transform(lms_output.reshape(-1, 1)).flatten()
        print("âœ… 2. LMS è‡ªé©æ‡‰æ¿¾æ³¢")
    except Exception as e:
        print(f"âŒ LMS æ¿¾æ³¢å¤±æ•—: {e}")
        results['2_lms'] = detrended
    
    # 3. RLS è‡ªé©æ‡‰æ¿¾æ³¢
    try:
        rls_filter = RLSFilter(n_taps=32, forgetting_factor=0.99)
        rls_output, rls_error = rls_filter.filter(normalized, desired_signal)
        results['3_rls'] = scaler.inverse_transform(rls_output.reshape(-1, 1)).flatten()
        print("âœ… 3. RLS è‡ªé©æ‡‰æ¿¾æ³¢")
    except Exception as e:
        print(f"âŒ RLS æ¿¾æ³¢å¤±æ•—: {e}")
        results['3_rls'] = detrended
    
    # 4. NLMS è‡ªé©æ‡‰æ¿¾æ³¢
    try:
        nlms_filter = NLMSFilter(n_taps=32, mu=0.5)
        nlms_output, nlms_error = nlms_filter.filter(normalized, desired_signal)
        results['4_nlms'] = scaler.inverse_transform(nlms_output.reshape(-1, 1)).flatten()
        print("âœ… 4. NLMS è‡ªé©æ‡‰æ¿¾æ³¢")
    except Exception as e:
        print(f"âŒ NLMS æ¿¾æ³¢å¤±æ•—: {e}")
        results['4_nlms'] = detrended
    
    # 5. DAF-CNN æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    cnn_model_path = f"mmWave_heart_amplitude/code/trained_models/daf_cnn_{distance}.h5"
    try:
        daf_cnn_filter = DeepAdaptiveFilter(input_dim=64, model_path=cnn_model_path, model_type='cnn')
        cnn_output = daf_cnn_filter.filter(detrended)
        results['5_daf_cnn'] = cnn_output
        print("âœ… 5. DAF-CNN æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    except Exception as e:
        print(f"âŒ DAF-CNN æ¿¾æ³¢å¤±æ•—: {e}")
        results['5_daf_cnn'] = detrended
    
    # 6. DAF-LSTM æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    lstm_model_path = f"mmWave_heart_amplitude/code/trained_models/daf_lstm_{distance}.h5"
    try:
        daf_lstm_filter = DeepAdaptiveFilter(input_dim=64, model_path=lstm_model_path, model_type='lstm')
        lstm_output = daf_lstm_filter.filter(detrended)
        results['6_daf_lstm'] = lstm_output
        print("âœ… 6. DAF-LSTM æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    except Exception as e:
        print(f"âŒ DAF-LSTM æ¿¾æ³¢å¤±æ•—: {e}")
        results['6_daf_lstm'] = detrended
    
    # 7. DAF-Hybrid æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    hybrid_model_path = f"mmWave_heart_amplitude/code/trained_models/daf_hybrid_{distance}.h5"
    try:
        daf_hybrid_filter = DeepAdaptiveFilter(input_dim=64, model_path=hybrid_model_path, model_type='hybrid')
        hybrid_output = daf_hybrid_filter.filter(detrended)
        results['7_daf_hybrid'] = hybrid_output
        print("âœ… 7. DAF-Hybrid æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    except Exception as e:
        print(f"âŒ DAF-Hybrid æ¿¾æ³¢å¤±æ•—: {e}")
        results['7_daf_hybrid'] = detrended
    
    print("ğŸ‰ æ‰€æœ‰è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å®Œæˆ!")
    
    return results

# %% [markdown]
# ## 4. è¦–è¦ºåŒ–å‡½æ•¸

# %%
def visualize_adaptive_filtering_methods(results, fs, ecg_signal=None, ecg_time=None, output_filename=None):
    """å¯è¦–åŒ–è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•èˆ‡ECGçš„æ¯”è¼ƒ (7å€‹å­åœ–)"""
    try:
        import matplotlib
        matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’æ¨¡å¼
        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        print(f"Font setting error: {e}")

    time = np.arange(len(results['1_raw'])) / fs
    
    # å®šç¾©7ç¨®æ–¹æ³•çš„è©³ç´°åç¨±å’Œé¡è‰²
    methods = [
        ('1_raw', 'åŸå§‹è¨Šè™Ÿ (Raw Signal)', 'blue'),
        ('2_lms', 'LMS è‡ªé©æ‡‰æ¿¾æ³¢å™¨', 'red'),
        ('3_rls', 'RLS è‡ªé©æ‡‰æ¿¾æ³¢å™¨', 'green'),
        ('4_nlms', 'NLMS è‡ªé©æ‡‰æ¿¾æ³¢å™¨', 'orange'),
        ('5_daf_cnn', 'DAF-CNN æ·±åº¦æ¿¾æ³¢å™¨', 'purple'),
        ('6_daf_lstm', 'DAF-LSTM æ·±åº¦æ¿¾æ³¢å™¨', 'brown'),
        ('7_daf_hybrid', 'DAF-Hybrid æ·±åº¦æ¿¾æ³¢å™¨', 'pink')
    ]

    plt.figure(figsize=(20, 28))  # å¢å¤§åœ–ç‰‡å°ºå¯¸
    
    for i, (method_key, method_name, color) in enumerate(methods):
        if method_key in results:
            ax = plt.subplot(4, 2, i+1)
            ax.plot(time, results[method_key], color=color, linewidth=1.0, label=f'mmWave {method_name}')
            ax.set_title(f'{method_name} vs ECG', fontsize=12, fontweight='bold')
            ax.set_ylabel('mmWave Amplitude', color=color, fontsize=10)
            ax.tick_params(axis='y', labelcolor=color)
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, 60)
            
            # æ·»åŠ ECGåƒè€ƒç·š
            if ecg_signal is not None and ecg_time is not None:
                ax_twin = ax.twinx()
                ax_twin.plot(ecg_time, ecg_signal, 'k-', alpha=0.6, linewidth=0.8, label='ECG Reference')
                ax_twin.set_ylabel('ECG Amplitude', color='k', fontsize=10)
                ax_twin.tick_params(axis='y', labelcolor='k')
                
                # æ·»åŠ åœ–ä¾‹
                lines1, labels1 = ax.get_legend_handles_labels()
                lines2, labels2 = ax_twin.get_legend_handles_labels()
                ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=8)
            else:
                ax.legend(loc='upper right', fontsize=8)
            
            # è¨­ç½®xè»¸åˆ»åº¦
            ax.set_xticks(np.arange(0, 61, 10))
            ax.set_xticklabels([str(x) for x in range(0, 61, 10)])
            
            if i >= 5:  # æœ€å¾Œä¸€è¡Œæ·»åŠ xè»¸æ¨™ç±¤
                ax.set_xlabel('Time (seconds)', fontsize=10)

    plt.tight_layout()
    
    # ä¿å­˜åœ–ç‰‡
    if output_filename is None:
        output_filename = 'Adaptive_Filtering_Methods_ECG_Comparison.png'
    
    plt.savefig(output_filename, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•æ¯”è¼ƒåœ–å·²å„²å­˜ç‚º: {output_filename}")
    plt.show()
    plt.close()

# %% [markdown]
# ## 5. è©•ä¼°æŒ‡æ¨™è¨ˆç®—å‡½æ•¸

# %%
def calculate_spectral_coherence(signal1, signal2, fs, nperseg=256):
    """è¨ˆç®—å…©å€‹è¨Šè™Ÿä¹‹é–“çš„é »è­œç›¸å¹²æ€§ (é »åŸŸæŒ‡æ¨™)"""
    try:
        # è¨ˆç®—ç›¸å¹²æ€§
        f, Cxy = coherence(signal1, signal2, fs, nperseg=nperseg)
        
        # è¨ˆç®—å¿ƒå¾‹é »ç‡ç¯„åœå…§ (0.8-3.0 Hz) çš„å¹³å‡ç›¸å¹²æ€§
        freq_mask = (f >= 0.8) & (f <= 3.0)
        if np.any(freq_mask):
            mean_coherence = np.mean(Cxy[freq_mask])
        else:
            mean_coherence = np.mean(Cxy)
            
        return mean_coherence
        
    except Exception as e:
        print(f"é »è­œç›¸å¹²æ€§è¨ˆç®—éŒ¯èª¤: {e}")
        return 0.0

def calculate_sample_entropy(signal_data, m=2, r=None):
    """è¨ˆç®—æ¨£æœ¬ç†µ (éç·šæ€§æŒ‡æ¨™)"""
    try:
        # æ­£è¦åŒ–è¨Šè™Ÿ
        signal_norm = (signal_data - np.mean(signal_data)) / np.std(signal_data)
        
        if r is None:
            r = 0.2 * np.std(signal_norm)
        
        N = len(signal_norm)
        
        def _maxdist(xi, xj, m):
            """è¨ˆç®—å…©å€‹æ¨¡å¼é–“çš„æœ€å¤§è·é›¢"""
            return max([abs(ua - va) for ua, va in zip(xi, xj)])
        
        def _phi(m):
            """è¨ˆç®—phi(m)"""
            patterns = np.array([signal_norm[i:i + m] for i in range(N - m + 1)])
            C = np.zeros(N - m + 1)
            
            for i in range(N - m + 1):
                template = patterns[i]
                for j in range(N - m + 1):
                    if _maxdist(template, patterns[j], m) <= r:
                        C[i] += 1.0
                        
            phi = np.mean([np.log(c / (N - m + 1.0)) for c in C if c > 0])
            return phi
        
        # è¨ˆç®—æ¨£æœ¬ç†µ
        phi_m = _phi(m)
        phi_m1 = _phi(m + 1)
        
        if phi_m == 0 or phi_m1 == 0:
            return 0.0
            
        sample_entropy = phi_m - phi_m1
        
        return sample_entropy
        
    except Exception as e:
        print(f"æ¨£æœ¬ç†µè¨ˆç®—éŒ¯èª¤: {e}")
        return 0.0

def analyze_adaptive_filtering_performance(results, ecg_signal, ecg_time, mmwave_time, fs=11.11):
    """åˆ†æè‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•çš„æ€§èƒ½"""
    print("\n" + "="*80)
    print("è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•æ€§èƒ½åˆ†æ")
    print("="*80)
    
    # æ¨™æº–åŒ–è¨Šè™Ÿä»¥é€²è¡Œå…¬å¹³æ¯”è¼ƒ
    def normalize_signal(signal):
        return (signal - np.mean(signal)) / np.std(signal)
    
    # é‡æ¡æ¨£ECGè¨Šè™Ÿåˆ°mmWaveçš„æ™‚é–“è»¸
    ecg_resampled = np.interp(mmwave_time, ecg_time, ecg_signal)
    ecg_norm = normalize_signal(ecg_resampled)
    
    # å®šç¾©æ¯”è¼ƒæ–¹æ³•çš„è©³ç´°åç¨±
    method_names = {
        '1_raw': '1.åŸå§‹è¨Šè™Ÿ',
        '2_lms': '2.LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨',
        '3_rls': '3.RLSè‡ªé©æ‡‰æ¿¾æ³¢å™¨',
        '4_nlms': '4.NLMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨',
        '5_daf_cnn': '5.DAF-CNNæ·±åº¦æ¿¾æ³¢å™¨',
        '6_daf_lstm': '6.DAF-LSTMæ·±åº¦æ¿¾æ³¢å™¨',
        '7_daf_hybrid': '7.DAF-Hybridæ·±åº¦æ¿¾æ³¢å™¨'
    }
    
    # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
    dtw_distances = {}           # æ™‚é–“åŸŸæŒ‡æ¨™
    spectral_coherences = {}     # é »åŸŸæŒ‡æ¨™  
    sample_entropies = {}        # éç·šæ€§æŒ‡æ¨™
    composite_scores = {}        # ç¶œåˆè¡¨ç¾åˆ†æ•¸
    
    for method_key, method_name in method_names.items():
        if method_key in results:
            signal_data = results[method_key]
            signal_norm = normalize_signal(signal_data)
            
            # 1. æ™‚é–“åŸŸæŒ‡æ¨™ - DTWè·é›¢è¨ˆç®—
            try:
                dtw_distance = dtw.distance(signal_norm, ecg_norm)
                dtw_distances[method_key] = dtw_distance
            except Exception as e:
                print(f"DTWè¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                dtw_distances[method_key] = float('inf')
            
            # 2. é »åŸŸæŒ‡æ¨™ - é »è­œç›¸å¹²æ€§è¨ˆç®—
            try:
                coherence_val = calculate_spectral_coherence(signal_norm, ecg_norm, fs)
                spectral_coherences[method_key] = coherence_val
            except Exception as e:
                print(f"é »è­œç›¸å¹²æ€§è¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                spectral_coherences[method_key] = 0.0
            
            # 3. éç·šæ€§æŒ‡æ¨™ - æ¨£æœ¬ç†µè¨ˆç®—
            try:
                signal_entropy = calculate_sample_entropy(signal_norm)
                ecg_entropy = calculate_sample_entropy(ecg_norm)
                entropy_similarity = 1 / (1 + abs(signal_entropy - ecg_entropy))
                sample_entropies[method_key] = entropy_similarity
            except Exception as e:
                print(f"æ¨£æœ¬ç†µè¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                sample_entropies[method_key] = 0.0
            
            # è¨ˆç®—ç¶œåˆè¡¨ç¾åˆ†æ•¸ (ä¸‰ç¨®æŒ‡æ¨™å„ä½”1/3)
            try:
                # DTWåˆ†æ•¸ï¼šè·é›¢è¶Šå°è¶Šå¥½ï¼Œè½‰æ›ç‚ºç›¸ä¼¼æ€§åˆ†æ•¸
                dtw_score = 1 / (1 + dtw_distances[method_key]) if dtw_distances[method_key] != float('inf') else 0
                
                # é »è­œç›¸å¹²æ€§åˆ†æ•¸ï¼šç›´æ¥ä½¿ç”¨ (0-1ä¹‹é–“ï¼Œè¶Šå¤§è¶Šå¥½)
                coherence_score = spectral_coherences[method_key]
                
                # æ¨£æœ¬ç†µç›¸ä¼¼æ€§åˆ†æ•¸ï¼šç›´æ¥ä½¿ç”¨ (0-1ä¹‹é–“ï¼Œè¶Šå¤§è¶Šå¥½)
                entropy_score = sample_entropies[method_key]
                
                # ç¶œåˆåˆ†æ•¸ï¼šä¸‰ç¨®æŒ‡æ¨™å„ä½”1/3
                composite_score = (dtw_score * (1/3) + coherence_score * (1/3) + 
                                 entropy_score * (1/3))
                composite_scores[method_key] = composite_score
                
            except Exception as e:
                print(f"ç¶œåˆåˆ†æ•¸è¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                composite_scores[method_key] = 0.0
    
    # ä»¥è¡¨æ ¼å½¢å¼é¡¯ç¤ºçµæœ
    print("\nè‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•æ€§èƒ½æ¯”è¼ƒè¡¨:")
    print("-" * 100)
    print("| {:^30} | {:^15} | {:^15} | {:^15} | {:^15} |".format(
        "æ¿¾æ³¢æ–¹æ³•", "DTWè·é›¢", "é »è­œç›¸å¹²æ€§", "æ¨£æœ¬ç†µç›¸ä¼¼æ€§", "ç¶œåˆè¡¨ç¾åˆ†æ•¸"))
    print("|" + "-"*32 + "+" + "-"*17 + "+" + "-"*17 + "+" + "-"*17 + "+" + "-"*17 + "|")
    
    for method_key in ['1_raw', '2_lms', '3_rls', '4_nlms', '5_daf_cnn', '6_daf_lstm', '7_daf_hybrid']:
        if method_key in results:
            method_name = method_names[method_key]
            dtw_val = dtw_distances.get(method_key, float('inf'))
            coherence_val = spectral_coherences.get(method_key, 0.0)
            entropy_val = sample_entropies.get(method_key, 0.0)
            composite_val = composite_scores.get(method_key, 0.0)
            
            print("| {:^30} | {:^15.4f} | {:^15.4f} | {:^15.4f} | {:^15.4f} |".format(
                method_name, dtw_val, coherence_val, entropy_val, composite_val))
    
    print("-" * 100)
    
    # ç¸½çµæœ€ä½³æ–¹æ³•
    print("\nå„é …æŒ‡æ¨™æœ€ä½³æ¿¾æ³¢æ–¹æ³•ç¸½çµ:")
    print("-" * 70)
    
    # DTWè·é›¢è¶Šå°è¶Šå¥½
    if dtw_distances:
        best_dtw = min(dtw_distances.items(), key=lambda x: x[1])
        print(f"â€¢ æ™‚é–“åŸŸæŒ‡æ¨™ (DTWè·é›¢æœ€å°): {method_names[best_dtw[0]]:<25} ({best_dtw[1]:.4f})")
    
    # é »è­œç›¸å¹²æ€§è¶Šå¤§è¶Šå¥½
    if spectral_coherences:
        best_coherence = max(spectral_coherences.items(), key=lambda x: x[1])
        print(f"â€¢ é »åŸŸæŒ‡æ¨™ (é »è­œç›¸å¹²æ€§æœ€é«˜): {method_names[best_coherence[0]]:<25} ({best_coherence[1]:.4f})")
    
    # æ¨£æœ¬ç†µç›¸ä¼¼æ€§è¶Šå¤§è¶Šå¥½
    if sample_entropies:
        best_entropy = max(sample_entropies.items(), key=lambda x: x[1])
        print(f"â€¢ éç·šæ€§æŒ‡æ¨™ (æ¨£æœ¬ç†µæœ€ç›¸ä¼¼): {method_names[best_entropy[0]]:<25} ({best_entropy[1]:.4f})")
    
    # ç¶œåˆè¡¨ç¾åˆ†æ•¸æœ€é«˜
    if composite_scores:
        best_composite = max(composite_scores.items(), key=lambda x: x[1])
        print(f"ğŸ† ç¶œåˆè¡¨ç¾åˆ†æ•¸æœ€é«˜: {method_names[best_composite[0]]:<25} ({best_composite[1]:.4f})")
        print(f"   (ä¸‰ç¨®æŒ‡æ¨™å„ä½”1/3æ¬Šé‡)")
    
    # æ·±åº¦å­¸ç¿’æ–¹æ³•æ’å
    deep_methods = ['5_daf_cnn', '6_daf_lstm', '7_daf_hybrid']
    deep_scores = {k: v for k, v in composite_scores.items() if k in deep_methods}
    if deep_scores:
        print(f"\nğŸ¤– æ·±åº¦å­¸ç¿’æ–¹æ³•æ’å:")
        sorted_deep = sorted(deep_scores.items(), key=lambda x: x[1], reverse=True)
        for i, (method_key, score) in enumerate(sorted_deep, 1):
            status = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
            print(f"   {status} {method_names[method_key]}: {score:.4f}")
    
    print("="*80)
    
    return {
        'dtw_distances': dtw_distances,
        'spectral_coherences': spectral_coherences,
        'sample_entropies': sample_entropies,
        'composite_scores': composite_scores,
        'method_names': method_names
    }

# %% [markdown]
# ## 6. ä¸»å‡½æ•¸

# %%
def main():
    """ä¸»ç¨‹å¼å…¥å£ - è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è¦–è¦ºåŒ–åˆ†æ"""
    print("ğŸš€ é–‹å§‹è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è¦–è¦ºåŒ–åˆ†æ...")
    
    # è¨­å®šæª”æ¡ˆè·¯å¾‘ï¼ˆè«‹æ ¹æ“šå¯¦éš›è·¯å¾‘ä¿®æ”¹ï¼‰
    mmwave_file_path = r"NEW_mmWave_PAPER/Output/merged_csv/45cm/05_20_2025_03_37_00.csv"
    ecg_file_path = r"NEW_mmWave_PAPER/Output/ECG Data/CSV/45cm/2025-5-20, 3ï€¢37â€¯AM-1.csv"
    distance = '45cm'  # å¯ä»¥ä¿®æ”¹ç‚ºå…¶ä»–è·é›¢: 30cm, 60cm, 90cm
    
    print(f"\n{'='*80}")
    print("è¼‰å…¥æ•¸æ“šæª”æ¡ˆ")
    print(f"{'='*80}")
    print(f"mmWave æª”æ¡ˆ: {mmwave_file_path}")
    print(f"ECG æª”æ¡ˆ: {ecg_file_path}")
    print(f"è·é›¢: {distance}")
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(mmwave_file_path):
        print(f"âŒ mmWaveæª”æ¡ˆä¸å­˜åœ¨: {mmwave_file_path}")
        return None
    
    if not os.path.exists(ecg_file_path):
        print(f"âŒ ECGæª”æ¡ˆä¸å­˜åœ¨: {ecg_file_path}")
        return None
    
    # è¼‰å…¥mmWaveæ•¸æ“š
    try:
        waveform_data, timestamps, heart_rates, frame_numbers, fs = load_and_preprocess_data(mmwave_file_path)
        print(f"âœ… mmWaveæ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œæ•¸æ“šé•·åº¦: {len(waveform_data)} æ¨£æœ¬")
    except Exception as e:
        print(f"âŒ mmWaveæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return None
    
    # è¼‰å…¥ECGæ•¸æ“š
    try:
        ecg_signal, ecg_time, ecg_fs = load_ecg_data(ecg_file_path)
        if ecg_signal is None or ecg_time is None:
            print(f"âŒ ECGæ•¸æ“šè¼‰å…¥å¤±æ•—")
            return None
        print(f"âœ… ECGæ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œæ•¸æ“šé•·åº¦: {len(ecg_signal)} æ¨£æœ¬")
    except Exception as e:
        print(f"âŒ ECGæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return None
    
    # é€²è¡Œè‡ªé©æ‡‰æ¿¾æ³¢è™•ç†
    print(f"\n{'='*80}")
    print("é–‹å§‹è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†")
    print(f"{'='*80}")
    
    try:
        results = process_adaptive_filtering_methods(waveform_data, fs, distance)
        print(f"âœ… è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å®Œæˆï¼Œå…±ç”¢ç”Ÿ {len(results)} ç¨®è™•ç†çµæœ")
    except Exception as e:
        print(f"âŒ è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å¤±æ•—: {e}")
        return None
    
    # ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨
    print(f"\n{'='*80}")
    print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
    print(f"{'='*80}")
    
    try:
        mmwave_time = np.arange(len(results['1_raw'])) / fs
        output_filename = f'Adaptive_Filtering_Methods_{distance}_ECG_Comparison.png'
        visualize_adaptive_filtering_methods(results, fs, ecg_signal, ecg_time, output_filename)
        print("âœ… è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå®Œæˆ")
    except Exception as e:
        print(f"âŒ è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
        return None
    
    # é€²è¡Œæ€§èƒ½åˆ†æ
    print(f"\n{'='*80}")
    print("é–‹å§‹æ€§èƒ½åˆ†æ")
    print(f"{'='*80}")
    
    try:
        mmwave_time = np.arange(len(results['1_raw'])) / fs
        analysis_results = analyze_adaptive_filtering_performance(results, ecg_signal, ecg_time, mmwave_time, fs)
        print("âœ… æ€§èƒ½åˆ†æå®Œæˆ")
    except Exception as e:
        print(f"âŒ æ€§èƒ½åˆ†æå¤±æ•—: {e}")
        return None
    
    print(f"\nğŸ‰ è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è¦–è¦ºåŒ–åˆ†æå®Œæˆ!")
    print(f"ğŸ“Š åœ–è¡¨å·²ä¿å­˜ç‚º: {output_filename}")
    print(f"ğŸ“‹ è«‹æŸ¥çœ‹ä¸Šæ–¹çš„æ€§èƒ½åˆ†æè¡¨æ ¼äº†è§£å„æ¿¾æ³¢æ–¹æ³•çš„æ•ˆæœ")
    
    return results, analysis_results

# %%
if __name__ == "__main__":
    results, analysis = main()
