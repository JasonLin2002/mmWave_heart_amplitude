# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
import os
from sklearn.preprocessing import StandardScaler
from scipy.stats import spearmanr
from dtaidistance import dtw
from scipy.signal import coherence
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import warnings
warnings.filterwarnings('ignore')

# %% [markdown]
# ## 1. æ•¸æ“šè¼‰å…¥å’Œé è™•ç†å‡½æ•¸

# %%
def load_ecg_data(ecg_path):
    """è¼‰å…¥ä¸¦é è™•ç†ECGæ•¸æ“š (æœ€å¾Œ60ç§’)"""
    print(f"æ­£åœ¨è¼‰å…¥ECGæ•¸æ“š: {ecg_path}")
    
    try:
        ecg_df = pd.read_csv(ecg_path)
        print(f"ECGæ•¸æ“šå½¢ç‹€: {ecg_df.shape}")
        print("\nECGæ•¸æ“šæ¬„ä½:")
        print(ecg_df.columns.tolist())
        
        # æª¢æŸ¥å¿…è¦çš„æ¬„ä½æ˜¯å¦å­˜åœ¨
        if 'time' not in ecg_df.columns or 'ecg' not in ecg_df.columns:
            print("éŒ¯èª¤: ECG CSV æª”æ¡ˆä¸­ç¼ºå°‘ 'time' æˆ– 'ecg' æ¬„ä½ã€‚")
            return None, None, None
            
        # ç§»é™¤ 'ecg' æ¬„ä½ä¸­ NaN çš„è¡Œï¼Œä¸¦ç¢ºä¿ 'time' ä¹Ÿç›¸æ‡‰ç§»é™¤
        df_cleaned = ecg_df.dropna(subset=['ecg'])
        
        ecg_signal = df_cleaned['ecg'].values
        timestamps_ns = df_cleaned['time'].values  # æ™‚é–“æˆ³ï¼ˆå¥ˆç§’ï¼‰
        
        if len(timestamps_ns) < 2:
            print("éŒ¯èª¤: ECG æ•¸æ“šä¸è¶³ä»¥è¨ˆç®—æ¡æ¨£ç‡ã€‚")
            return None, None, None
        
        # ECGæ¡æ¨£ç‡ç‚º130Hz
        ecg_fs = 130.0
        print(f"ECG è¨­å®šæ¡æ¨£ç‡: {ecg_fs:.2f} Hz")
        
        # è½‰æ›æ™‚é–“æˆ³ç‚ºç§’ä¸¦å–æœ€å¾Œ60ç§’
        times_s = timestamps_ns * 1e-9
        N = len(ecg_signal)
        total_duration = times_s[-1] - times_s[0] if N > 1 else 0
        display_duration = 60.0
        
        if total_duration <= display_duration:
            start_idx = 0
            end_idx = N
        else:
            end_time = times_s[-1]
            start_time = end_time - display_duration
            start_idx = np.searchsorted(times_s, start_time, side="left")
            end_idx = N
            
        # å–æœ€å¾Œ60ç§’çš„æ•¸æ“š
        ecg_signal = ecg_signal[start_idx:end_idx]
        timestamps_ns = timestamps_ns[start_idx:end_idx]
        times_s = times_s[start_idx:end_idx]
        
        # å‰µå»ºç›¸å°æ™‚é–“è»¸ï¼ˆå¾0é–‹å§‹ï¼‰
        ecg_time = times_s - times_s[0]
        
        print(f"ECGä¿¡è™Ÿé•·åº¦: {len(ecg_signal)} æ¨£æœ¬ ({len(ecg_signal)/ecg_fs:.1f} ç§’)")
        print(f"ECGæ™‚é–“ç¯„åœ: {ecg_time[0]:.1f} åˆ° {ecg_time[-1]:.1f} ç§’")
        
        return ecg_signal, ecg_time, ecg_fs
        
    except Exception as e:
        print(f"è¼‰å…¥ECGæ•¸æ“šéŒ¯èª¤: {e}")
        return None, None, None

def load_and_preprocess_data(file_path):
    """è®€å–ä¸¦é è™•ç†é›·é”å¿ƒå¾‹æŒ¯å¹…æ•¸æ“š (åªä¿ç•™æœ€å¾Œ60ç§’)"""
    print(f"è®€å–æª”æ¡ˆ: {file_path}")
    df = pd.read_csv(file_path)
    print(f"æ•¸æ“šå½¢ç‹€: {df.shape}")
    print("\næ•¸æ“šé è¦½:")
    print(df.head())
    fs = 11.11  # å›ºå®šæ¡æ¨£ç‡
    print(f"\nä¼°è¨ˆæ¡æ¨£ç‡: {fs:.2f} Hz")
    df_sorted = df.sort_values(by='Frame_Number')
    waveform_data = df_sorted['Heart_Waveform'].values
    timestamps = df_sorted['Timestamp'].values
    heart_rates = df_sorted['Heart_Rate'].values
    frame_numbers = df_sorted['Frame_Number'].values

    # åªä¿ç•™æœ€å¾Œ60ç§’
    N = len(waveform_data)
    time_axis_full = np.arange(N) / fs
    total_duration = time_axis_full[-1] if N > 1 else 0
    display_duration = 60.0
    if total_duration <= display_duration:
        start_idx = 0
        end_idx = N
    else:
        end_time = time_axis_full[-1]
        start_time = end_time - display_duration
        start_idx = np.searchsorted(time_axis_full, start_time, side="left")
        end_idx = N
    waveform_data = waveform_data[start_idx:end_idx]
    timestamps = timestamps[start_idx:end_idx]
    heart_rates = heart_rates[start_idx:end_idx]
    frame_numbers = frame_numbers[start_idx:end_idx]
    return waveform_data, timestamps, heart_rates, frame_numbers, fs

# %% [markdown]
# ## 2. è‡ªé©æ‡‰æ¿¾æ³¢å™¨å¯¦ä½œ

# %%
class LMSFilter:
    """æœ€å°å‡æ–¹ (LMS) è‡ªé©æ‡‰æ¿¾æ³¢å™¨"""
    def __init__(self, filter_length=32, step_size=0.01):
        self.filter_length = filter_length
        self.step_size = step_size
        self.weights = np.zeros(filter_length)
        self.input_buffer = np.zeros(filter_length)
        
    def filter(self, input_signal, desired_signal=None):
        """
        LMSæ¿¾æ³¢è™•ç†
        Args:
            input_signal: è¼¸å…¥ä¿¡è™Ÿ
            desired_signal: æœŸæœ›ä¿¡è™Ÿ (å¦‚æœç‚ºNoneï¼Œå‰‡ä½¿ç”¨å»¶é²ç‰ˆæœ¬çš„è¼¸å…¥ä¿¡è™Ÿ)
        """
        if desired_signal is None:
            # ä½¿ç”¨å»¶é²ç‰ˆæœ¬çš„è¼¸å…¥ä¿¡è™Ÿä½œç‚ºæœŸæœ›ä¿¡è™Ÿ
            desired_signal = np.concatenate([np.zeros(10), input_signal[:-10]])
        
        output_signal = np.zeros(len(input_signal))
        
        for n in range(len(input_signal)):
            # æ›´æ–°è¼¸å…¥ç·©è¡å€
            self.input_buffer = np.roll(self.input_buffer, 1)
            self.input_buffer[0] = input_signal[n]
            
            # è¨ˆç®—æ¿¾æ³¢å™¨è¼¸å‡º
            y_n = np.dot(self.weights, self.input_buffer)
            output_signal[n] = y_n
            
            # è¨ˆç®—èª¤å·®
            error = desired_signal[n] - y_n
            
            # æ›´æ–°æ¬Šé‡ (LMSç®—æ³•)
            self.weights += self.step_size * error * self.input_buffer
            
        return output_signal

class NLMSFilter:
    """æ­£è¦åŒ–æœ€å°å‡æ–¹ (NLMS) è‡ªé©æ‡‰æ¿¾æ³¢å™¨"""
    def __init__(self, filter_length=32, step_size=0.1):
        self.filter_length = filter_length
        self.step_size = step_size
        self.weights = np.zeros(filter_length)
        self.input_buffer = np.zeros(filter_length)
        self.epsilon = 1e-10  # é¿å…é™¤é›¶
        
    def filter(self, input_signal, desired_signal=None):
        """
        NLMSæ¿¾æ³¢è™•ç†
        """
        if desired_signal is None:
            # ä½¿ç”¨å»¶é²ç‰ˆæœ¬çš„è¼¸å…¥ä¿¡è™Ÿä½œç‚ºæœŸæœ›ä¿¡è™Ÿ
            desired_signal = np.concatenate([np.zeros(10), input_signal[:-10]])
        
        output_signal = np.zeros(len(input_signal))
        
        for n in range(len(input_signal)):
            # æ›´æ–°è¼¸å…¥ç·©è¡å€
            self.input_buffer = np.roll(self.input_buffer, 1)
            self.input_buffer[0] = input_signal[n]
            
            # è¨ˆç®—æ¿¾æ³¢å™¨è¼¸å‡º
            y_n = np.dot(self.weights, self.input_buffer)
            output_signal[n] = y_n
            
            # è¨ˆç®—èª¤å·®
            error = desired_signal[n] - y_n
            
            # è¨ˆç®—æ­£è¦åŒ–å› å­
            norm_factor = np.dot(self.input_buffer, self.input_buffer) + self.epsilon
            
            # æ›´æ–°æ¬Šé‡ (NLMSç®—æ³•)
            self.weights += (self.step_size / norm_factor) * error * self.input_buffer
            
        return output_signal

class RLSFilter:
    """éè¿´æœ€å°å¹³æ–¹ (RLS) è‡ªé©æ‡‰æ¿¾æ³¢å™¨"""
    def __init__(self, filter_length=32, forgetting_factor=0.99, delta=1.0):
        self.filter_length = filter_length
        self.lambda_ = forgetting_factor
        self.weights = np.zeros(filter_length)
        self.P = np.eye(filter_length) / delta  # é€†ç›¸é—œçŸ©é™£
        self.input_buffer = np.zeros(filter_length)
        
    def filter(self, input_signal, desired_signal=None):
        """
        RLSæ¿¾æ³¢è™•ç†
        """
        if desired_signal is None:
            # ä½¿ç”¨å»¶é²ç‰ˆæœ¬çš„è¼¸å…¥ä¿¡è™Ÿä½œç‚ºæœŸæœ›ä¿¡è™Ÿ
            desired_signal = np.concatenate([np.zeros(10), input_signal[:-10]])
        
        output_signal = np.zeros(len(input_signal))
        
        for n in range(len(input_signal)):
            # æ›´æ–°è¼¸å…¥ç·©è¡å€
            self.input_buffer = np.roll(self.input_buffer, 1)
            self.input_buffer[0] = input_signal[n]
            
            # è¨ˆç®—æ¿¾æ³¢å™¨è¼¸å‡º
            y_n = np.dot(self.weights, self.input_buffer)
            output_signal[n] = y_n
            
            # è¨ˆç®—èª¤å·®
            error = desired_signal[n] - y_n
            
            # RLSæ›´æ–°
            k = self.P @ self.input_buffer
            alpha = 1.0 / (self.lambda_ + self.input_buffer @ k)
            k = alpha * k
            
            # æ›´æ–°æ¬Šé‡
            self.weights += k * error
            
            # æ›´æ–°é€†ç›¸é—œçŸ©é™£
            self.P = (self.P - np.outer(k, self.input_buffer @ self.P)) / self.lambda_
            
        return output_signal

class DeepAdaptiveFilter:
    """æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (DAF)"""
    def __init__(self, input_dim=32, hidden_units=64):
        self.input_dim = input_dim
        self.hidden_units = hidden_units
        self.model = None
        self.is_trained = False
        
    def build_model(self):
        """å»ºæ§‹æ·±åº¦å­¸ç¿’æ¨¡å‹"""
        model = keras.Sequential([
            layers.Input(shape=(self.input_dim,)),
            layers.Dense(self.hidden_units, activation='tanh'),
            layers.Dense(self.hidden_units//2, activation='tanh'),
            layers.Dense(self.hidden_units//4, activation='tanh'),
            layers.Dense(1, activation='linear')
        ])
        
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model
        
    def prepare_training_data(self, input_signal, desired_signal=None):
        """æº–å‚™è¨“ç·´æ•¸æ“š"""
        if desired_signal is None:
            # ä½¿ç”¨å»¶é²ç‰ˆæœ¬çš„è¼¸å…¥ä¿¡è™Ÿä½œç‚ºæœŸæœ›ä¿¡è™Ÿ
            desired_signal = np.concatenate([np.zeros(10), input_signal[:-10]])
            
        # å‰µå»ºæ»‘å‹•çª—å£æ•¸æ“š
        X = []
        y = []
        
        for i in range(self.input_dim, len(input_signal)):
            window = input_signal[i-self.input_dim:i]
            X.append(window)
            y.append(desired_signal[i])
            
        return np.array(X), np.array(y)
    
    def filter(self, input_signal, desired_signal=None):
        """
        æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†
        """
        # æº–å‚™è¨“ç·´æ•¸æ“š
        X_train, y_train = self.prepare_training_data(input_signal, desired_signal)
        
        # å»ºæ§‹ä¸¦è¨“ç·´æ¨¡å‹
        if not self.is_trained:
            self.model = self.build_model()
            
            # è¨“ç·´æ¨¡å‹ (ä½¿ç”¨è¼ƒå°‘çš„epochä»¥æ¸›å°‘è¨ˆç®—æ™‚é–“)
            self.model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)
            self.is_trained = True
        
        # ç”Ÿæˆè¼¸å‡ºä¿¡è™Ÿ
        output_signal = np.zeros(len(input_signal))
        
        # å‰é¢éƒ¨åˆ†ç”¨é›¶å¡«å……
        output_signal[:self.input_dim] = 0
        
        # ä½¿ç”¨æ¨¡å‹é æ¸¬å¾Œé¢éƒ¨åˆ†
        predictions = self.model.predict(X_train, verbose=0)
        output_signal[self.input_dim:] = predictions.flatten()
        
        return output_signal

# %% [markdown]
# ## 3. è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å‡½æ•¸

# %%
def apply_detrend(signal_data):
    """å»è¶¨å‹¢è™•ç†"""
    return signal.detrend(signal_data)

def process_adaptive_filtering_methods(waveform_data, fs):
    """
    4ç¨®è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è™•ç†
    
    è™•ç†æµç¨‹ï¼š
    1. åŸå§‹è¨Šè™Ÿ
    2. LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    3. RLSè‡ªé©æ‡‰æ¿¾æ³¢å™¨  
    4. NLMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    5. æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (DAF)
    """
    
    results = {}
    
    print("ğŸ”„ é–‹å§‹è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†...")
    
    # 1. åŸå§‹è¨Šè™Ÿ
    results['1_raw'] = waveform_data
    print("âœ… 1. åŸå§‹è¨Šè™Ÿ")
    
    # åŸºæœ¬å‰è™•ç† - å»è¶¨å‹¢
    detrended = apply_detrend(waveform_data)
    
    # æ­£è¦åŒ–ä¿¡è™Ÿä»¥æ”¹å–„æ¿¾æ³¢å™¨æ€§èƒ½
    normalized_signal = (detrended - np.mean(detrended)) / np.std(detrended)
    
    # 2. LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    try:
        lms_filter = LMSFilter(filter_length=32, step_size=0.01)
        lms_output = lms_filter.filter(normalized_signal)
        results['2_lms'] = lms_output
        print("âœ… 2. LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    except Exception as e:
        print(f"âŒ LMSæ¿¾æ³¢å™¨éŒ¯èª¤: {e}")
        results['2_lms'] = normalized_signal
    
    # 3. RLSè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    try:
        rls_filter = RLSFilter(filter_length=32, forgetting_factor=0.99)
        rls_output = rls_filter.filter(normalized_signal)
        results['3_rls'] = rls_output
        print("âœ… 3. RLSè‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    except Exception as e:
        print(f"âŒ RLSæ¿¾æ³¢å™¨éŒ¯èª¤: {e}")
        results['3_rls'] = normalized_signal
    
    # 4. NLMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    try:
        nlms_filter = NLMSFilter(filter_length=32, step_size=0.1)
        nlms_output = nlms_filter.filter(normalized_signal)
        results['4_nlms'] = nlms_output
        print("âœ… 4. NLMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    except Exception as e:
        print(f"âŒ NLMSæ¿¾æ³¢å™¨éŒ¯èª¤: {e}")
        results['4_nlms'] = normalized_signal
    
    # 5. æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (DAF) - å˜—è©¦è¼‰å…¥é è¨“ç·´æ¨¡å‹
    try:
        # é è¨“ç·´æ¨¡å‹è·¯å¾‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        pretrained_model_path = "mmWave_heart_amplitude/code/trained_models/daf_hybrid_45cm.h5"
        
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨é è¨“ç·´æ¨¡å‹
        if os.path.exists(pretrained_model_path):
            print(f"ğŸ” ç™¼ç¾é è¨“ç·´æ¨¡å‹: {pretrained_model_path}")
            daf_filter = DeepAdaptiveFilter(input_dim=64, model_path=pretrained_model_path, model_type='hybrid')
        else:
            print("âš ï¸  æœªæ‰¾åˆ°é è¨“ç·´æ¨¡å‹ï¼Œå°‡ä½¿ç”¨å³æ™‚è¨“ç·´")
            daf_filter = DeepAdaptiveFilter(input_dim=64, model_path=None, model_type='hybrid')
        
        daf_output = daf_filter.filter(normalized_signal)
        results['5_daf'] = daf_output
        print("âœ… 5. æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (DAF)")
    except Exception as e:
        print(f"âŒ æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨éŒ¯èª¤: {e}")
        results['5_daf'] = normalized_signal
    
    print("ğŸ‰ æ‰€æœ‰è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å®Œæˆ!")
    
    return results

# %% [markdown]
# ## 4. è¦–è¦ºåŒ–å‡½æ•¸

# %%
def visualize_adaptive_filtering_methods(results, fs, ecg_signal=None, ecg_time=None, output_filename=None):
    """å¯è¦–åŒ–5ç¨®è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•èˆ‡ECGçš„æ¯”è¼ƒ"""
    try:
        import matplotlib
        matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’æ¨¡å¼
        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
    except Exception as e:
        print(f"å­—é«”è¨­å®šéŒ¯èª¤: {e}")

    time = np.arange(len(results['1_raw'])) / fs
    
    # å®šç¾©5ç¨®æ–¹æ³•çš„è©³ç´°åç¨±å’Œé¡è‰²
    methods = [
        ('1_raw', 'åŸå§‹è¨Šè™Ÿ (Raw Signal)', 'blue'),
        ('2_lms', 'LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨', 'red'),
        ('3_rls', 'RLSè‡ªé©æ‡‰æ¿¾æ³¢å™¨', 'green'),
        ('4_nlms', 'NLMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨', 'orange'),
        ('5_daf', 'æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (DAF)', 'purple')
    ]

    plt.figure(figsize=(20, 20))
    
    for i, (method_key, method_name, color) in enumerate(methods):
        if method_key in results:
            ax = plt.subplot(3, 2, i+1)
            ax.plot(time, results[method_key], color=color, linewidth=1.0, label=f'mmWave {method_name}')
            ax.set_title(f'{method_name} vs ECG', fontsize=14, fontweight='bold')
            ax.set_ylabel('mmWaveæŒ¯å¹…', color=color, fontsize=12)
            ax.tick_params(axis='y', labelcolor=color)
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, 60)
            
            # æ·»åŠ ECGåƒè€ƒç·š
            if ecg_signal is not None and ecg_time is not None:
                ax_twin = ax.twinx()
                ax_twin.plot(ecg_time, ecg_signal, 'k-', alpha=0.6, linewidth=0.8, label='ECGåƒè€ƒ')
                ax_twin.set_ylabel('ECGæŒ¯å¹…', color='k', fontsize=12)
                ax_twin.tick_params(axis='y', labelcolor='k')
                
                # æ·»åŠ åœ–ä¾‹
                lines1, labels1 = ax.get_legend_handles_labels()
                lines2, labels2 = ax_twin.get_legend_handles_labels()
                ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=10)
            else:
                ax.legend(loc='upper right', fontsize=10)
            
            # è¨­ç½®xè»¸åˆ»åº¦
            ax.set_xticks(np.arange(0, 61, 10))
            ax.set_xticklabels([str(x) for x in range(0, 61, 10)])
            
            if i >= 3:  # ä¸‹æ–¹çš„åœ–æ·»åŠ xè»¸æ¨™ç±¤
                ax.set_xlabel('æ™‚é–“ (ç§’)', fontsize=12)

    plt.tight_layout()
    
    # ä¿å­˜åœ–ç‰‡
    if output_filename is None:
        output_filename = 'Adaptive_Filters_ECG_Comparison.png'
    
    plt.savefig(output_filename, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š è‡ªé©æ‡‰æ¿¾æ³¢å™¨æ¯”è¼ƒåœ–å·²å„²å­˜ç‚º: {output_filename}")
    plt.show()
    plt.close()

# %% [markdown]
# ## 5. è©•ä¼°æŒ‡æ¨™è¨ˆç®—å‡½æ•¸

# %%
def calculate_spectral_coherence(signal1, signal2, fs, nperseg=256):
    """è¨ˆç®—å…©å€‹è¨Šè™Ÿä¹‹é–“çš„é »è­œç›¸å¹²æ€§ (é »åŸŸæŒ‡æ¨™)"""
    try:
        # è¨ˆç®—ç›¸å¹²æ€§
        f, Cxy = coherence(signal1, signal2, fs, nperseg=nperseg)
        
        # è¨ˆç®—å¿ƒå¾‹é »ç‡ç¯„åœå…§ (0.8-3.0 Hz) çš„å¹³å‡ç›¸å¹²æ€§
        freq_mask = (f >= 0.8) & (f <= 3.0)
        if np.any(freq_mask):
            mean_coherence = np.mean(Cxy[freq_mask])
        else:
            mean_coherence = np.mean(Cxy)
            
        return mean_coherence
        
    except Exception as e:
        print(f"é »è­œç›¸å¹²æ€§è¨ˆç®—éŒ¯èª¤: {e}")
        return 0.0

def calculate_sample_entropy(signal_data, m=2, r=None):
    """è¨ˆç®—æ¨£æœ¬ç†µ (éç·šæ€§æŒ‡æ¨™)"""
    try:
        # æ­£è¦åŒ–è¨Šè™Ÿ
        signal_norm = (signal_data - np.mean(signal_data)) / np.std(signal_data)
        
        if r is None:
            r = 0.2 * np.std(signal_norm)
        
        N = len(signal_norm)
        
        def _maxdist(xi, xj, m):
            """è¨ˆç®—å…©å€‹æ¨¡å¼é–“çš„æœ€å¤§è·é›¢"""
            return max([abs(ua - va) for ua, va in zip(xi, xj)])
        
        def _phi(m):
            """è¨ˆç®—phi(m)"""
            patterns = np.array([signal_norm[i:i + m] for i in range(N - m + 1)])
            C = np.zeros(N - m + 1)
            
            for i in range(N - m + 1):
                template = patterns[i]
                for j in range(N - m + 1):
                    if _maxdist(template, patterns[j], m) <= r:
                        C[i] += 1.0
                        
            phi = np.mean([np.log(c / (N - m + 1.0)) for c in C if c > 0])
            return phi
        
        # è¨ˆç®—æ¨£æœ¬ç†µ
        phi_m = _phi(m)
        phi_m1 = _phi(m + 1)
        
        if phi_m == 0 or phi_m1 == 0:
            return 0.0
            
        sample_entropy = phi_m - phi_m1
        
        return sample_entropy
        
    except Exception as e:
        print(f"æ¨£æœ¬ç†µè¨ˆç®—éŒ¯èª¤: {e}")
        return 0.0

def analyze_adaptive_filtering_performance(results, ecg_signal, ecg_time, mmwave_time, fs=11.11):
    """åˆ†æ5ç¨®è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•çš„æ€§èƒ½"""
    print("\n" + "="*80)
    print("è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•æ€§èƒ½åˆ†æ")
    print("="*80)
    
    # æ¨™æº–åŒ–è¨Šè™Ÿä»¥é€²è¡Œå…¬å¹³æ¯”è¼ƒ
    def normalize_signal(signal):
        return (signal - np.mean(signal)) / np.std(signal)
    
    # é‡æ¡æ¨£ECGè¨Šè™Ÿåˆ°mmWaveçš„æ™‚é–“è»¸
    ecg_resampled = np.interp(mmwave_time, ecg_time, ecg_signal)
    ecg_norm = normalize_signal(ecg_resampled)
    
    # å®šç¾©æ¯”è¼ƒæ–¹æ³•çš„è©³ç´°åç¨±
    method_names = {
        '1_raw': '1.åŸå§‹è¨Šè™Ÿ',
        '2_lms': '2.LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨',
        '3_rls': '3.RLSè‡ªé©æ‡‰æ¿¾æ³¢å™¨',
        '4_nlms': '4.NLMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨',
        '5_daf': '5.æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨(DAF)'
    }
    
    # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
    dtw_distances = {}           # æ™‚é–“åŸŸæŒ‡æ¨™
    spectral_coherences = {}     # é »åŸŸæŒ‡æ¨™  
    sample_entropies = {}        # éç·šæ€§æŒ‡æ¨™
    composite_scores = {}        # ç¶œåˆè¡¨ç¾åˆ†æ•¸
    
    for method_key, method_name in method_names.items():
        if method_key in results:
            signal_data = results[method_key]
            signal_norm = normalize_signal(signal_data)
            
            # 1. æ™‚é–“åŸŸæŒ‡æ¨™ - DTWè·é›¢è¨ˆç®—
            try:
                dtw_distance = dtw.distance(signal_norm, ecg_norm)
                dtw_distances[method_key] = dtw_distance
            except Exception as e:
                print(f"DTWè¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                dtw_distances[method_key] = float('inf')
            
            # 2. é »åŸŸæŒ‡æ¨™ - é »è­œç›¸å¹²æ€§è¨ˆç®—
            try:
                coherence_val = calculate_spectral_coherence(signal_norm, ecg_norm, fs)
                spectral_coherences[method_key] = coherence_val
            except Exception as e:
                print(f"é »è­œç›¸å¹²æ€§è¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                spectral_coherences[method_key] = 0.0
            
            # 3. éç·šæ€§æŒ‡æ¨™ - æ¨£æœ¬ç†µè¨ˆç®—
            try:
                signal_entropy = calculate_sample_entropy(signal_norm)
                ecg_entropy = calculate_sample_entropy(ecg_norm)
                entropy_similarity = 1 / (1 + abs(signal_entropy - ecg_entropy))
                sample_entropies[method_key] = entropy_similarity
            except Exception as e:
                print(f"æ¨£æœ¬ç†µè¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                sample_entropies[method_key] = 0.0
            
            # è¨ˆç®—ç¶œåˆè¡¨ç¾åˆ†æ•¸ (ä¸‰ç¨®æŒ‡æ¨™å„ä½”1/3)
            try:
                # DTWåˆ†æ•¸ï¼šè·é›¢è¶Šå°è¶Šå¥½ï¼Œè½‰æ›ç‚ºç›¸ä¼¼æ€§åˆ†æ•¸
                dtw_score = 1 / (1 + dtw_distances[method_key]) if dtw_distances[method_key] != float('inf') else 0
                
                # é »è­œç›¸å¹²æ€§åˆ†æ•¸ï¼šç›´æ¥ä½¿ç”¨ (0-1ä¹‹é–“ï¼Œè¶Šå¤§è¶Šå¥½)
                coherence_score = spectral_coherences[method_key]
                
                # æ¨£æœ¬ç†µç›¸ä¼¼æ€§åˆ†æ•¸ï¼šç›´æ¥ä½¿ç”¨ (0-1ä¹‹é–“ï¼Œè¶Šå¤§è¶Šå¥½)
                entropy_score = sample_entropies[method_key]
                
                # ç¶œåˆåˆ†æ•¸ï¼šä¸‰ç¨®æŒ‡æ¨™å„ä½”1/3
                composite_score = (dtw_score * (1/3) + coherence_score * (1/3) + 
                                 entropy_score * (1/3))
                composite_scores[method_key] = composite_score
                
            except Exception as e:
                print(f"ç¶œåˆåˆ†æ•¸è¨ˆç®—éŒ¯èª¤ ({method_name}): {e}")
                composite_scores[method_key] = 0.0
    
    # ä»¥è¡¨æ ¼å½¢å¼é¡¯ç¤ºçµæœ
    print("\nè‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•æ€§èƒ½æ¯”è¼ƒè¡¨:")
    print("-" * 100)
    print("| {:^25} | {:^15} | {:^15} | {:^15} | {:^15} |".format(
        "æ¿¾æ³¢æ–¹æ³•", "DTWè·é›¢", "é »è­œç›¸å¹²æ€§", "æ¨£æœ¬ç†µç›¸ä¼¼æ€§", "ç¶œåˆè¡¨ç¾åˆ†æ•¸"))
    print("|" + "-"*27 + "+" + "-"*17 + "+" + "-"*17 + "+" + "-"*17 + "+" + "-"*17 + "|")
    
    for method_key in ['1_raw', '2_lms', '3_rls', '4_nlms', '5_daf']:
        if method_key in results:
            method_name = method_names[method_key]
            dtw_val = dtw_distances.get(method_key, float('inf'))
            coherence_val = spectral_coherences.get(method_key, 0.0)
            entropy_val = sample_entropies.get(method_key, 0.0)
            composite_val = composite_scores.get(method_key, 0.0)
            
            print("| {:^25} | {:^15.4f} | {:^15.4f} | {:^15.4f} | {:^15.4f} |".format(
                method_name, dtw_val, coherence_val, entropy_val, composite_val))
    
    print("-" * 100)
    
    # ç¸½çµæœ€ä½³æ–¹æ³•
    print("\nå„é …æŒ‡æ¨™æœ€ä½³æ¿¾æ³¢æ–¹æ³•ç¸½çµ:")
    print("-" * 60)
    
    # DTWè·é›¢è¶Šå°è¶Šå¥½
    if dtw_distances:
        best_dtw = min(dtw_distances.items(), key=lambda x: x[1])
        print(f"â€¢ æ™‚é–“åŸŸæŒ‡æ¨™ (DTWè·é›¢æœ€å°): {method_names[best_dtw[0]]:<25} ({best_dtw[1]:.4f})")
    
    # é »è­œç›¸å¹²æ€§è¶Šå¤§è¶Šå¥½
    if spectral_coherences:
        best_coherence = max(spectral_coherences.items(), key=lambda x: x[1])
        print(f"â€¢ é »åŸŸæŒ‡æ¨™ (é »è­œç›¸å¹²æ€§æœ€é«˜): {method_names[best_coherence[0]]:<25} ({best_coherence[1]:.4f})")
    
    # æ¨£æœ¬ç†µç›¸ä¼¼æ€§è¶Šå¤§è¶Šå¥½
    if sample_entropies:
        best_entropy = max(sample_entropies.items(), key=lambda x: x[1])
        print(f"â€¢ éç·šæ€§æŒ‡æ¨™ (æ¨£æœ¬ç†µæœ€ç›¸ä¼¼): {method_names[best_entropy[0]]:<25} ({best_entropy[1]:.4f})")
    
    # ç¶œåˆè¡¨ç¾åˆ†æ•¸æœ€é«˜
    if composite_scores:
        best_composite = max(composite_scores.items(), key=lambda x: x[1])
        print(f"ğŸ† ç¶œåˆè¡¨ç¾åˆ†æ•¸æœ€é«˜: {method_names[best_composite[0]]:<25} ({best_composite[1]:.4f})")
        print(f"   (ä¸‰ç¨®æŒ‡æ¨™å„ä½”1/3æ¬Šé‡)")
    
    print("="*80)
    
    return {
        'dtw_distances': dtw_distances,
        'spectral_coherences': spectral_coherences,
        'sample_entropies': sample_entropies,
        'composite_scores': composite_scores,
        'method_names': method_names
    }

# %% [markdown]
# ## 6. ä¸»å‡½æ•¸

# %%
def main():
    """ä¸»ç¨‹å¼å…¥å£ - è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è¦–è¦ºåŒ–åˆ†æ"""
    print("ğŸš€ é–‹å§‹è‡ªé©æ‡‰æ¿¾æ³¢æ–¹æ³•è¦–è¦ºåŒ–åˆ†æ...")
    
    # è¨­å®šæª”æ¡ˆè·¯å¾‘ï¼ˆè«‹æ ¹æ“šå¯¦éš›è·¯å¾‘ä¿®æ”¹ï¼‰
    mmwave_file_path = r"C:\Users\jk121\Documents\Code\NEW_mmWave_PAPER\Output\merged_csv\45cm\05_20_2025_03_37_00.csv"
    ecg_file_path = r"C:\Users\jk121\Documents\Code\NEW_mmWave_PAPER\Output\ECG Data\CSV\45cm\2025-5-20, 3ï€¢37â€¯AM-1.csv"
    
    print(f"\n{'='*80}")
    print("è¼‰å…¥æ•¸æ“šæª”æ¡ˆ")
    print(f"{'='*80}")
    print(f"mmWave æª”æ¡ˆ: {mmwave_file_path}")
    print(f"ECG æª”æ¡ˆ: {ecg_file_path}")
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(mmwave_file_path):
        print(f"âŒ mmWaveæª”æ¡ˆä¸å­˜åœ¨: {mmwave_file_path}")
        return None
    
    if not os.path.exists(ecg_file_path):
        print(f"âŒ ECGæª”æ¡ˆä¸å­˜åœ¨: {ecg_file_path}")
        return None
    
    # è¼‰å…¥mmWaveæ•¸æ“š
    try:
        waveform_data, timestamps, heart_rates, frame_numbers, fs = load_and_preprocess_data(mmwave_file_path)
        print(f"âœ… mmWaveæ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œæ•¸æ“šé•·åº¦: {len(waveform_data)} æ¨£æœ¬")
    except Exception as e:
        print(f"âŒ mmWaveæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return None
    
    # è¼‰å…¥ECGæ•¸æ“š
    try:
        ecg_signal, ecg_time, ecg_fs = load_ecg_data(ecg_file_path)
        if ecg_signal is None or ecg_time is None:
            print(f"âŒ ECGæ•¸æ“šè¼‰å…¥å¤±æ•—")
            return None
        print(f"âœ… ECGæ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œæ•¸æ“šé•·åº¦: {len(ecg_signal)} æ¨£æœ¬")
    except Exception as e:
        print(f"âŒ ECGæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return None
    
    # é€²è¡Œè‡ªé©æ‡‰æ¿¾æ³¢è™•ç†
    print(f"\n{'='*80}")
    print("é–‹å§‹è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†")
    print(f"{'='*80}")
    
    try:
        results = process_adaptive_filtering_methods(waveform_data, fs)
        print(f"âœ… è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å®Œæˆï¼Œå…±ç”¢ç”Ÿ {len(results)} ç¨®è™•ç†çµæœ")
    except Exception as e:
        print(f"âŒ è‡ªé©æ‡‰æ¿¾æ³¢è™•ç†å¤±æ•—: {e}")
        return None
    
    # ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨
    print(f"\n{'='*80}")
    print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
    print(f"{'='*80}")
    
    try:
        mmwave_time = np.arange(len(results['1_raw'])) / fs
        output_filename = 'Adaptive_Filters_ECG_Comparison.png'
        visualize_adaptive_filtering_methods(results, fs, ecg_signal, ecg_time, output_filename)
        print("âœ… è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå®Œæˆ")
    except Exception as e:
        print(f"âŒ è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
        return None
    
    # é€²è¡Œæ€§èƒ½åˆ†æ
    print(f"\n{'='*80}")
    print("é–‹å§‹æ€§èƒ½åˆ†æ")
    print(f"{'='*80}")
    
    try:
        mmwave_time = np.arange(len(results['1_raw'])) / fs
        analysis_results = analyze_adaptive_filtering_performance(results, ecg_signal, ecg_time, mmwave_time, fs)
        print("âœ… æ€§èƒ½åˆ†æå®Œæˆ")
    except Exception as e:
        print(f"âŒ æ€§èƒ½åˆ†æå¤±æ•—: {e}")
        return None
    
    print(f"\nğŸ‰ æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨è¦–è¦ºåŒ–åˆ†æå®Œæˆ!")
    print(f"ğŸ“Š åœ–è¡¨å·²ä¿å­˜ç‚º: {output_filename}")
    print(f"ğŸ“‹ è«‹æŸ¥çœ‹ä¸Šæ–¹çš„æ€§èƒ½åˆ†æè¡¨æ ¼äº†è§£å„æ¿¾æ³¢æ–¹æ³•çš„æ•ˆæœ")
    print(f"\nğŸ”§ æ¿¾æ³¢å™¨èªªæ˜:")
    print(f"   â€¢ LMS: æœ€å°å‡æ–¹è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼Œæ”¶æ–‚é€Ÿåº¦é©ä¸­")
    print(f"   â€¢ RLS: éè¿´æœ€å°å¹³æ–¹è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼Œæ”¶æ–‚é€Ÿåº¦å¿«ä½†è¨ˆç®—è¤‡é›œ")
    print(f"   â€¢ NLMS: æ­£è¦åŒ–LMSè‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼Œç©©å®šæ€§è¼ƒä½³")
    print(f"   â€¢ DAF-CNN: å·ç©ç¥ç¶“ç¶²è·¯æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼Œå–„æ–¼ç‰¹å¾µæå–")
    print(f"   â€¢ DAF-LSTM: é•·çŸ­æœŸè¨˜æ†¶ç¶²è·¯æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼Œé©åˆæ™‚åºå»ºæ¨¡")
    print(f"   â€¢ DAF-Hybrid: CNN+LSTMæ··åˆæ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼Œç¶œåˆå„ªå‹¢æœ€ä½³")
    print(f"   â€¢ DAF-Transformer: åŸºæ–¼æ³¨æ„åŠ›æ©Ÿåˆ¶çš„æ·±åº¦è‡ªé©æ‡‰æ¿¾æ³¢å™¨ (å¦‚å¯ç”¨)")
    
    return results, analysis_results

# %%
if __name__ == "__main__":
    results, analysis = main()
